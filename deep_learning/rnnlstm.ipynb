{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SqzyV06rYiLm"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import time\n",
    "from tensorflow.python.layers.core import Dense\n",
    "from tensorflow.python.ops.rnn_cell_impl import _zero_state_tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>intro</th>\n",
       "      <th>article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60 хвилин на реакцію. Як ефективно протидіяти ...</td>\n",
       "      <td>Вищі урядовці мають відреагувати на появу воро...</td>\n",
       "      <td>Одрі Танг любить висловлюватися точно. Під час...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Фільм про нас. Cеріал «Чорнобиль» показує вади...</td>\n",
       "      <td>Серіал має найбільший рейтинг серед усіх інших...</td>\n",
       "      <td>«Влада погано комунікує з суспільством», – чує...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Київські візерунки. Зіграйте у гру й перевірте...</td>\n",
       "      <td>У Києві є близько сорока мікрорайонів. Наскіль...</td>\n",
       "      <td>Що бачить художник, коли дивиться на карту Киє...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Протистояння медіа та соцмереж під час виборів...</td>\n",
       "      <td>Вибори президента України в 2019 році були уні...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Модераторка дискусії Діана Дуцик з Могилянсько...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Філарет проти канонічності. Як українські прав...</td>\n",
       "      <td>Колишній патріарх УПЦ КП Філарет — нерозлучний...</td>\n",
       "      <td>Попри це, патріархові Філарету потрібно віддат...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Міліцейський саботаж і суддівська змова. Як ст...</td>\n",
       "      <td>Позови переважно складені за принципом «килимо...</td>\n",
       "      <td>Автор: Ольга Худецька, журналіст, член Атестац...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Моніторинг тем, які піднімає російська дезінфо...</td>\n",
       "      <td>Обмеження дослідження: теми російської пропага...</td>\n",
       "      <td>Російські дезінформаційні видання з окупованих...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\"Автономія\" Донбасу в складі України – це крах...</td>\n",
       "      <td>Обрання нового президента з риторикою «про пош...</td>\n",
       "      <td>Втім, саме по собі надання «окремим районам До...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Щоб зупинити реванш, патріотичні партії мають ...</td>\n",
       "      <td>Існує реальна загроза формування однопартійної...</td>\n",
       "      <td>Видавши сумнівний з точки зору законності Указ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>«Мондеґрін». Культовий письменник із Донецька ...</td>\n",
       "      <td>Події в «Мондеґріні» розгортаються в режимі фа...</td>\n",
       "      <td>Прозова новинка, що побачила світ напередодні ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>В Україні і греко-католики, і православні з за...</td>\n",
       "      <td>Їх так багато, що більшість народу сприймає ці...</td>\n",
       "      <td>Гуцульська архітектурна школа, волинська, беса...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Основна причина паводків — забудова заплав. Ру...</td>\n",
       "      <td>Останнім часом увага суспільства прикута до си...</td>\n",
       "      <td>Звісно, водоохоронну роль лісів важко заперечи...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Сім'я без сексу. Радянський тоталітаризм вбива...</td>\n",
       "      <td>Чоловіки, не маючи здорового контакту зі своїм...</td>\n",
       "      <td>В інтерв’ю Текстам я розповіла про те, як трав...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Реваншизм, популізм і прагнення тотальної влад...</td>\n",
       "      <td>Невизначеність зовнішньополітичного курсу, роз...</td>\n",
       "      <td>Найголовніше, навіть не те, що сказав новий Пр...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Зрадофіли, порохоботи та журнашлюхи. Хроніки р...</td>\n",
       "      <td>Останніми роками наш лексикон поповнився купою...</td>\n",
       "      <td>Тексти не раз критикували українську журналіст...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>“Гра престолів”: справжня причина, чому фани н...</td>\n",
       "      <td>Відома дослідниця впливу технологій на суспіль...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Моніторинг тем, які піднімає російська пропага...</td>\n",
       "      <td>Ми починаємо регулярну публікацію моніторингу ...</td>\n",
       "      <td>Короткий висновок: Відповідно до російської ко...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Перетоки голосів між І-м та ІІ-м туром виборів...</td>\n",
       "      <td>Виборці Гриценка з Галичини та Києва дали найб...</td>\n",
       "      <td>Це друга й остання частина статті про те, наск...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Закон про мову: що він регулює і як це працюва...</td>\n",
       "      <td>Документ докладно визначає, як саме захищаєтьс...</td>\n",
       "      <td>Сьогодні, 15 травня, Петро Порошенко підписав ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Who voted for Zelenskiy after all? Most of Tym...</td>\n",
       "      <td>We have no intention to draw psychological por...</td>\n",
       "      <td>In order to simulate the distribution of the v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Чому в Україні зміннюються пори року, а на екв...</td>\n",
       "      <td>Багато хто вважає, що температура на нашій пла...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Руки незрячих. Ними плетуть сталеві канати і ч...</td>\n",
       "      <td>З-під широких чорних окулярів, скам’янілих на ...</td>\n",
       "      <td>З 1 квітня почали діяти нові державні будівель...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Страсті Партріарха. Владні амбіції Філарета шк...</td>\n",
       "      <td>Під час створення Православної церкви України ...</td>\n",
       "      <td>Православна Церква України створена 15 грудня ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Справжній Голобородько. Тезка «Слуги народу» п...</td>\n",
       "      <td>\"Він ворожий до української культури. Його усп...</td>\n",
       "      <td>У них нема нічого спільного, окрім імені й прі...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Король Інстаграму? Ні, продукт телебачення. Хт...</td>\n",
       "      <td>Більшість зірок Інстаграму – дуже оголені та м...</td>\n",
       "      <td>Про цьогорічну президентську виборчу кампанію ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Психологічні травми, отримані в радянські часи...</td>\n",
       "      <td>Коли на особисту травму нашаровується травма с...</td>\n",
       "      <td>— Сьогодні ми живемо у відносно спокійному сві...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Дев'ять причин, чому програв Порошенко, і що й...</td>\n",
       "      <td>Олігархічні телеканали, неякісні розслідування...</td>\n",
       "      <td>Журналісти плакали на фінальній прес-конференц...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Хто ж (все-таки) голосував за Зеленського? Най...</td>\n",
       "      <td>Ми не будемо малювати психологічні портрети чи...</td>\n",
       "      <td>Щоб змоделювати, хто з виборців першого туру  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Бурштинова республіка потрапила в художню літе...</td>\n",
       "      <td>У романі Василя Тибеля «Бурштин» будні нелегал...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>Гроші на бізнес від держави. В розвинених краї...</td>\n",
       "      <td>Банк Англії надає фінансування тим приватним б...</td>\n",
       "      <td>В Україні близько 2 мільйонів малих підприємст...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>Мовні квоти на ТБ. Чому «ліберали» не праві і ...</td>\n",
       "      <td>Менеджери телеканалів, крім упередженого ставл...</td>\n",
       "      <td>Нещодавно ухвалений парламентом Закон «щодо мо...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>«Відкриті дані» держструктур: лише 8% у машино...</td>\n",
       "      <td>На Єдиному державному порталі відкритих даних ...</td>\n",
       "      <td>Держава  збирає і продукує багато інформації, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>Медицина в Грузії: чого досягла радикальна реф...</td>\n",
       "      <td>Багатоповерхова будівля Республіканської лікар...</td>\n",
       "      <td>— Доброго дня. Я журналіст із України. Хочу на...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>Як покращити якість державних закупівель та мі...</td>\n",
       "      <td>Дослідження ґрунтується на аналізі 35 тисяч «п...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Для порівняння старої та нової систем закупіве...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>Перша офіційна компенсація від МВС за дії \"Бер...</td>\n",
       "      <td>Дружина загиблого майданівця передала половину...</td>\n",
       "      <td>Сергій Дідич - 45-річний депутат Городенківськ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>Дев’ять тисяч доларів на даху. Як живеться вла...</td>\n",
       "      <td>Садибу Сергія Попова легко знайти в заплутаних...</td>\n",
       "      <td>Зараз Сергій має 30 панелей, і, для прикладу, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>Розхитати Донбас. Як депутати демократичних си...</td>\n",
       "      <td>Влада зменшує тиск і критику, а регіонали не с...</td>\n",
       "      <td>Революція гідності і війна з Росією розморозил...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>Боротьба з уявною «ЛГБТ-загрозою» стає реальни...</td>\n",
       "      <td>Не має значення, як Ви ставитись до проблем се...</td>\n",
       "      <td>У листопаді минулого року першим тривожним «дз...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>12 міфів \"про Захід\". Все не так, як здається</td>\n",
       "      <td>Коли комусь з українців не подобається якесь у...</td>\n",
       "      <td>У якомусь українському ресторані туалети зачин...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>Чиновникам наплювати. Уряд провалив власні пла...</td>\n",
       "      <td>У Миколаєві на Львівщині завдяки переведенню к...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Держава здатна значно скоротити використання і...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>1000 кілометрів Змієвих валів під Києвом. Хто ...</td>\n",
       "      <td>На півдні від Києва можна зустріти дивні земля...</td>\n",
       "      <td>Про це читайте, вивчайте Вали на картах та див...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>Український експорт до ЄС: сировина, сировина ...</td>\n",
       "      <td>Коли ціни на метал, руду, зерно та олію ростут...</td>\n",
       "      <td>&lt;a href='#'&gt;&lt;img alt='Експорт українських това...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>Черги за біометричними паспортами. Чому більші...</td>\n",
       "      <td>О 6-й ранку біля скляної будівлі сервісного це...</td>\n",
       "      <td>6 квітня 521 голосом «за» Європейський парламе...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>Найнеймовірніші причини відкласти. Огляд судів...</td>\n",
       "      <td>Судячи з тактики, яку повально демонструє у су...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>\"Тюрми СБУ\", Окуєва-не-чеченка, радикали захоп...</td>\n",
       "      <td>Ми прослідкували, як і ким  поширювалися три н...</td>\n",
       "      <td>Це нормально, бо люди не повинні проводити вес...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>Злочини на ґрунті ненависті. Визнати не можна ...</td>\n",
       "      <td>Наприкінці травня активісти націоналістичних у...</td>\n",
       "      <td>Правозахисники, з якими спілкувались ТЕКСТИ, о...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>П'ять куль у лежачого. Справи Майдану: суди по...</td>\n",
       "      <td>Беркутівці з «чорної роти»; командир роти харк...</td>\n",
       "      <td>Загалом існує близько 50 справ Майдану, по біл...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>Бійці колчаківських фронтів. Хто, крім бійців ...</td>\n",
       "      <td>В Україні сотні ветеранських організацій, які ...</td>\n",
       "      <td>Питання — куди йдуть ветеранські гроші, особли...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>Сила землі. Три гектари забезпечують родині до...</td>\n",
       "      <td>Невелика земельна ділянка поблизу Києва забезп...</td>\n",
       "      <td>— Останніми роками стала частіше до церкви ход...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>Міф про 75% української на телебаченні. Все пр...</td>\n",
       "      <td>Закон справді зміцнює позиції української мови...</td>\n",
       "      <td>Прийнятий Верховною Радою законопроект №5313, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>Українці помирають рано. Чому так відбувається...</td>\n",
       "      <td>Наші громадяни живуть на 11 років менше за євр...</td>\n",
       "      <td>Сталося це після Революції  Гідності. Одна моя...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>Євробачення-2017: погуляли на мільярд. Найбіль...</td>\n",
       "      <td>Двісті тридцять мільйонів гривень Київ вклав в...</td>\n",
       "      <td>2016 року Київ перерахував  Суспільному ТБ (ко...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>5 книжок із Арсеналу: від спогадів підпільниці...</td>\n",
       "      <td>Закінчився щорічний Книжковий Арсенал у Києві,...</td>\n",
       "      <td>1. Володимир Єрмоленко. Ловець океану. — Львів...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>Паркувальний армагеддон. Чому право ставити ма...</td>\n",
       "      <td>Як запобігти появі автомобільних заторів, забр...</td>\n",
       "      <td>За інформацією ТЕКСТІВ, київська мерія схиляєт...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>Мільйон з гектара. Дрібні фермерські господарс...</td>\n",
       "      <td>Практикою багатьох країн доведено, що фермерсь...</td>\n",
       "      <td>Володимир Завадовський керує невеликим аграрни...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>План анексії Білорусі. Як Лукашенко поставив с...</td>\n",
       "      <td>Протягом 2017 року російсько-український кордо...</td>\n",
       "      <td>Контракт між Міноборони РФ та залізницею перед...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>Бути іншим. Пісня переможця Євробачення-17 від...</td>\n",
       "      <td>Чому на Євробаченні  переміг саме португалець ...</td>\n",
       "      <td>На Spotify зазначено, що характеристика «енерг...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>516 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "0    60 хвилин на реакцію. Як ефективно протидіяти ...   \n",
       "1    Фільм про нас. Cеріал «Чорнобиль» показує вади...   \n",
       "2    Київські візерунки. Зіграйте у гру й перевірте...   \n",
       "3    Протистояння медіа та соцмереж під час виборів...   \n",
       "4                                                  NaN   \n",
       "5    Філарет проти канонічності. Як українські прав...   \n",
       "6    Міліцейський саботаж і суддівська змова. Як ст...   \n",
       "7    Моніторинг тем, які піднімає російська дезінфо...   \n",
       "8    \"Автономія\" Донбасу в складі України – це крах...   \n",
       "9    Щоб зупинити реванш, патріотичні партії мають ...   \n",
       "10   «Мондеґрін». Культовий письменник із Донецька ...   \n",
       "11   В Україні і греко-католики, і православні з за...   \n",
       "12   Основна причина паводків — забудова заплав. Ру...   \n",
       "13   Сім'я без сексу. Радянський тоталітаризм вбива...   \n",
       "14   Реваншизм, популізм і прагнення тотальної влад...   \n",
       "15   Зрадофіли, порохоботи та журнашлюхи. Хроніки р...   \n",
       "16   “Гра престолів”: справжня причина, чому фани н...   \n",
       "17   Моніторинг тем, які піднімає російська пропага...   \n",
       "18   Перетоки голосів між І-м та ІІ-м туром виборів...   \n",
       "19   Закон про мову: що він регулює і як це працюва...   \n",
       "20   Who voted for Zelenskiy after all? Most of Tym...   \n",
       "21   Чому в Україні зміннюються пори року, а на екв...   \n",
       "22   Руки незрячих. Ними плетуть сталеві канати і ч...   \n",
       "23   Страсті Партріарха. Владні амбіції Філарета шк...   \n",
       "24   Справжній Голобородько. Тезка «Слуги народу» п...   \n",
       "25   Король Інстаграму? Ні, продукт телебачення. Хт...   \n",
       "26   Психологічні травми, отримані в радянські часи...   \n",
       "27   Дев'ять причин, чому програв Порошенко, і що й...   \n",
       "28   Хто ж (все-таки) голосував за Зеленського? Най...   \n",
       "29   Бурштинова республіка потрапила в художню літе...   \n",
       "..                                                 ...   \n",
       "486  Гроші на бізнес від держави. В розвинених краї...   \n",
       "487  Мовні квоти на ТБ. Чому «ліберали» не праві і ...   \n",
       "488  «Відкриті дані» держструктур: лише 8% у машино...   \n",
       "489  Медицина в Грузії: чого досягла радикальна реф...   \n",
       "490  Як покращити якість державних закупівель та мі...   \n",
       "491                                                NaN   \n",
       "492  Перша офіційна компенсація від МВС за дії \"Бер...   \n",
       "493  Дев’ять тисяч доларів на даху. Як живеться вла...   \n",
       "494  Розхитати Донбас. Як депутати демократичних си...   \n",
       "495  Боротьба з уявною «ЛГБТ-загрозою» стає реальни...   \n",
       "496      12 міфів \"про Захід\". Все не так, як здається   \n",
       "497  Чиновникам наплювати. Уряд провалив власні пла...   \n",
       "498                                                NaN   \n",
       "499  1000 кілометрів Змієвих валів під Києвом. Хто ...   \n",
       "500  Український експорт до ЄС: сировина, сировина ...   \n",
       "501  Черги за біометричними паспортами. Чому більші...   \n",
       "502  Найнеймовірніші причини відкласти. Огляд судів...   \n",
       "503  \"Тюрми СБУ\", Окуєва-не-чеченка, радикали захоп...   \n",
       "504  Злочини на ґрунті ненависті. Визнати не можна ...   \n",
       "505  П'ять куль у лежачого. Справи Майдану: суди по...   \n",
       "506  Бійці колчаківських фронтів. Хто, крім бійців ...   \n",
       "507  Сила землі. Три гектари забезпечують родині до...   \n",
       "508  Міф про 75% української на телебаченні. Все пр...   \n",
       "509  Українці помирають рано. Чому так відбувається...   \n",
       "510  Євробачення-2017: погуляли на мільярд. Найбіль...   \n",
       "511  5 книжок із Арсеналу: від спогадів підпільниці...   \n",
       "512  Паркувальний армагеддон. Чому право ставити ма...   \n",
       "513  Мільйон з гектара. Дрібні фермерські господарс...   \n",
       "514  План анексії Білорусі. Як Лукашенко поставив с...   \n",
       "515  Бути іншим. Пісня переможця Євробачення-17 від...   \n",
       "\n",
       "                                                 intro  \\\n",
       "0    Вищі урядовці мають відреагувати на появу воро...   \n",
       "1    Серіал має найбільший рейтинг серед усіх інших...   \n",
       "2    У Києві є близько сорока мікрорайонів. Наскіль...   \n",
       "3    Вибори президента України в 2019 році були уні...   \n",
       "4    Модераторка дискусії Діана Дуцик з Могилянсько...   \n",
       "5    Колишній патріарх УПЦ КП Філарет — нерозлучний...   \n",
       "6    Позови переважно складені за принципом «килимо...   \n",
       "7    Обмеження дослідження: теми російської пропага...   \n",
       "8    Обрання нового президента з риторикою «про пош...   \n",
       "9    Існує реальна загроза формування однопартійної...   \n",
       "10   Події в «Мондеґріні» розгортаються в режимі фа...   \n",
       "11   Їх так багато, що більшість народу сприймає ці...   \n",
       "12   Останнім часом увага суспільства прикута до си...   \n",
       "13   Чоловіки, не маючи здорового контакту зі своїм...   \n",
       "14   Невизначеність зовнішньополітичного курсу, роз...   \n",
       "15   Останніми роками наш лексикон поповнився купою...   \n",
       "16   Відома дослідниця впливу технологій на суспіль...   \n",
       "17   Ми починаємо регулярну публікацію моніторингу ...   \n",
       "18   Виборці Гриценка з Галичини та Києва дали найб...   \n",
       "19   Документ докладно визначає, як саме захищаєтьс...   \n",
       "20   We have no intention to draw psychological por...   \n",
       "21   Багато хто вважає, що температура на нашій пла...   \n",
       "22   З-під широких чорних окулярів, скам’янілих на ...   \n",
       "23   Під час створення Православної церкви України ...   \n",
       "24   \"Він ворожий до української культури. Його усп...   \n",
       "25   Більшість зірок Інстаграму – дуже оголені та м...   \n",
       "26   Коли на особисту травму нашаровується травма с...   \n",
       "27   Олігархічні телеканали, неякісні розслідування...   \n",
       "28   Ми не будемо малювати психологічні портрети чи...   \n",
       "29   У романі Василя Тибеля «Бурштин» будні нелегал...   \n",
       "..                                                 ...   \n",
       "486  Банк Англії надає фінансування тим приватним б...   \n",
       "487  Менеджери телеканалів, крім упередженого ставл...   \n",
       "488  На Єдиному державному порталі відкритих даних ...   \n",
       "489  Багатоповерхова будівля Республіканської лікар...   \n",
       "490  Дослідження ґрунтується на аналізі 35 тисяч «п...   \n",
       "491  Для порівняння старої та нової систем закупіве...   \n",
       "492  Дружина загиблого майданівця передала половину...   \n",
       "493  Садибу Сергія Попова легко знайти в заплутаних...   \n",
       "494  Влада зменшує тиск і критику, а регіонали не с...   \n",
       "495  Не має значення, як Ви ставитись до проблем се...   \n",
       "496  Коли комусь з українців не подобається якесь у...   \n",
       "497  У Миколаєві на Львівщині завдяки переведенню к...   \n",
       "498  Держава здатна значно скоротити використання і...   \n",
       "499  На півдні від Києва можна зустріти дивні земля...   \n",
       "500  Коли ціни на метал, руду, зерно та олію ростут...   \n",
       "501  О 6-й ранку біля скляної будівлі сервісного це...   \n",
       "502  Судячи з тактики, яку повально демонструє у су...   \n",
       "503  Ми прослідкували, як і ким  поширювалися три н...   \n",
       "504  Наприкінці травня активісти націоналістичних у...   \n",
       "505  Беркутівці з «чорної роти»; командир роти харк...   \n",
       "506  В Україні сотні ветеранських організацій, які ...   \n",
       "507  Невелика земельна ділянка поблизу Києва забезп...   \n",
       "508  Закон справді зміцнює позиції української мови...   \n",
       "509  Наші громадяни живуть на 11 років менше за євр...   \n",
       "510  Двісті тридцять мільйонів гривень Київ вклав в...   \n",
       "511  Закінчився щорічний Книжковий Арсенал у Києві,...   \n",
       "512  Як запобігти появі автомобільних заторів, забр...   \n",
       "513  Практикою багатьох країн доведено, що фермерсь...   \n",
       "514  Протягом 2017 року російсько-український кордо...   \n",
       "515  Чому на Євробаченні  переміг саме португалець ...   \n",
       "\n",
       "                                               article  \n",
       "0    Одрі Танг любить висловлюватися точно. Під час...  \n",
       "1    «Влада погано комунікує з суспільством», – чує...  \n",
       "2    Що бачить художник, коли дивиться на карту Киє...  \n",
       "3                                                  NaN  \n",
       "4                                                  NaN  \n",
       "5    Попри це, патріархові Філарету потрібно віддат...  \n",
       "6    Автор: Ольга Худецька, журналіст, член Атестац...  \n",
       "7    Російські дезінформаційні видання з окупованих...  \n",
       "8    Втім, саме по собі надання «окремим районам До...  \n",
       "9    Видавши сумнівний з точки зору законності Указ...  \n",
       "10   Прозова новинка, що побачила світ напередодні ...  \n",
       "11   Гуцульська архітектурна школа, волинська, беса...  \n",
       "12   Звісно, водоохоронну роль лісів важко заперечи...  \n",
       "13   В інтерв’ю Текстам я розповіла про те, як трав...  \n",
       "14   Найголовніше, навіть не те, що сказав новий Пр...  \n",
       "15   Тексти не раз критикували українську журналіст...  \n",
       "16                                                 NaN  \n",
       "17   Короткий висновок: Відповідно до російської ко...  \n",
       "18   Це друга й остання частина статті про те, наск...  \n",
       "19   Сьогодні, 15 травня, Петро Порошенко підписав ...  \n",
       "20   In order to simulate the distribution of the v...  \n",
       "21                                                 NaN  \n",
       "22   З 1 квітня почали діяти нові державні будівель...  \n",
       "23   Православна Церква України створена 15 грудня ...  \n",
       "24   У них нема нічого спільного, окрім імені й прі...  \n",
       "25   Про цьогорічну президентську виборчу кампанію ...  \n",
       "26   — Сьогодні ми живемо у відносно спокійному сві...  \n",
       "27   Журналісти плакали на фінальній прес-конференц...  \n",
       "28   Щоб змоделювати, хто з виборців першого туру  ...  \n",
       "29                                                 NaN  \n",
       "..                                                 ...  \n",
       "486  В Україні близько 2 мільйонів малих підприємст...  \n",
       "487  Нещодавно ухвалений парламентом Закон «щодо мо...  \n",
       "488  Держава  збирає і продукує багато інформації, ...  \n",
       "489  — Доброго дня. Я журналіст із України. Хочу на...  \n",
       "490                                                NaN  \n",
       "491                                                NaN  \n",
       "492  Сергій Дідич - 45-річний депутат Городенківськ...  \n",
       "493  Зараз Сергій має 30 панелей, і, для прикладу, ...  \n",
       "494  Революція гідності і війна з Росією розморозил...  \n",
       "495  У листопаді минулого року першим тривожним «дз...  \n",
       "496  У якомусь українському ресторані туалети зачин...  \n",
       "497                                                NaN  \n",
       "498                                                NaN  \n",
       "499  Про це читайте, вивчайте Вали на картах та див...  \n",
       "500  <a href='#'><img alt='Експорт українських това...  \n",
       "501  6 квітня 521 голосом «за» Європейський парламе...  \n",
       "502                                                NaN  \n",
       "503  Це нормально, бо люди не повинні проводити вес...  \n",
       "504  Правозахисники, з якими спілкувались ТЕКСТИ, о...  \n",
       "505  Загалом існує близько 50 справ Майдану, по біл...  \n",
       "506  Питання — куди йдуть ветеранські гроші, особли...  \n",
       "507  — Останніми роками стала частіше до церкви ход...  \n",
       "508  Прийнятий Верховною Радою законопроект №5313, ...  \n",
       "509  Сталося це після Революції  Гідності. Одна моя...  \n",
       "510  2016 року Київ перерахував  Суспільному ТБ (ко...  \n",
       "511  1. Володимир Єрмоленко. Ловець океану. — Львів...  \n",
       "512  За інформацією ТЕКСТІВ, київська мерія схиляєт...  \n",
       "513  Володимир Завадовський керує невеликим аграрни...  \n",
       "514  Контракт між Міноборони РФ та залізницею перед...  \n",
       "515  На Spotify зазначено, що характеристика «енерг...  \n",
       "\n",
       "[516 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles = pd.read_csv(\"../data/texty_news.csv\")\n",
    "articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title      12\n",
       "intro       0\n",
       "article    47\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = articles.dropna()\n",
    "articles = articles.drop(['intro'], 1)\n",
    "articles = articles.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60 хвилин на реакцію. Як ефективно протидіяти ...</td>\n",
       "      <td>Одрі Танг любить висловлюватися точно. Під час...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Фільм про нас. Cеріал «Чорнобиль» показує вади...</td>\n",
       "      <td>«Влада погано комунікує з суспільством», – чує...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Київські візерунки. Зіграйте у гру й перевірте...</td>\n",
       "      <td>Що бачить художник, коли дивиться на карту Киє...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Філарет проти канонічності. Як українські прав...</td>\n",
       "      <td>Попри це, патріархові Філарету потрібно віддат...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Міліцейський саботаж і суддівська змова. Як ст...</td>\n",
       "      <td>Автор: Ольга Худецька, журналіст, член Атестац...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  60 хвилин на реакцію. Як ефективно протидіяти ...   \n",
       "1  Фільм про нас. Cеріал «Чорнобиль» показує вади...   \n",
       "2  Київські візерунки. Зіграйте у гру й перевірте...   \n",
       "3  Філарет проти канонічності. Як українські прав...   \n",
       "4  Міліцейський саботаж і суддівська змова. Як ст...   \n",
       "\n",
       "                                             article  \n",
       "0  Одрі Танг любить висловлюватися точно. Під час...  \n",
       "1  «Влада погано комунікує з суспільством», – чує...  \n",
       "2  Що бачить художник, коли дивиться на карту Киє...  \n",
       "3  Попри це, патріархові Філарету потрібно віддат...  \n",
       "4  Автор: Ольга Худецька, журналіст, член Атестац...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Фільм про нас. Cеріал «Чорнобиль» показує вади радянської системи, дотепер вкорінені в Україні\n",
      "Article: «Влада погано комунікує з суспільством», – чуємо ми сьогодні. У цього явища багато причин, і одна з них криється у Чорнобильській трагедії. Аварію, причини й наслідки якої попервах погано розуміли навіть у Кремлі, усіляко приховували, применшували. Власне, для СРСР це було «доброю традицією». ЧАЕС не була першою техногенною катастрофою (варто задати хоча б Киштимську аварію на Уралі 1957-го).  Однак масштаб та інформаційний ефект Чорнобиля – нечуваний. Відтоді серед українців залишилася помітна травма: коли трапляється щось надзвичайне, влада вочевидь брехатиме і викривлятиме інформацію. Тому в нашому соціумі є дуже велике поле для чуток і маніпуляцій.  Вже в добу соцмереж нерідко з’являються фейкові повідомлення в стилі «чоловік моєї подруги працює пожежником у Чорнобильські зоні, і він сказав»… – а далі йдуть різні варіації жахалок. Це «заходить» і через 30 років після вибуху на АЕС, бо надто вже цинічною була брехня тоді.  «Брехатимуть і далі», – впевнені мільйони наших громадян і сьогодні. В незалежній Україні немає тотальної цензури, всемогутнього КГБ, імперських амбіцій. Однак чиновникам під час надзвичайних ситуацій доводиться докладати чимало зусиль, щоб викликати бодай якусь довіру до себе. Порівняно недавня історія: 2007-го року біля села Ожидів на Львівщині перекинулися цистерни з фосфором. Генерал Олександр Кузьмук, який був на той час віце-прем’єром, приїхав на місце подій і, щоб заспокоїти місцевих мешканців, скуштував огірок з городу місцевої мешканки.  На перший погляд, типова «ляшковщина». Але й пережиток Чорнобиля також. В однойменному серіалі є промовиста сцена, коли шахтар кидає на стіл перед московськими чиновниками респіратор зі словами: «Якби вони(респіратори) допомагали, ви б самі носили їх, не знімаючи».  Чорнобильська брехня породила недовіру, коли представники влади змушені переконувати людей власним емпіричним прикладом чи бодай персональною присутністю. Торік було масове отруєння дітей в Черкасах, Володимир Гройсман особисто літав їх провідати. Люди молодшого покоління висміяли це у численних фотожабах. А для покоління, яке пережило Чорнобиль, особиста присутність очільника уряду стала переконливим спростуванням неймовірних чуток про екологічну ситуацію в місті.  В серіалі доволі промовисто показано ієрархію радянського чиновництва: дрібні місцеві функціонери прагнуть обдурити столичних «шишок», уникнути відповідальності, зіграти на некомпетентності високих гостей. Коли прип’ятські можновладці зустрічають Бориса Щербину, то впевнені, що зуміють навіщати локшини на вуха цьому кремлівському партійному бонзі.  Їхньому здивуванню немає меж, коли «товариш із ЦК» демонструє їм знання з атомної енергетики. Так нерідко буває й з українськими чиновниками: візитерам із Києва прагнуть продемонструвати показуху, не пускати «далі фасаду», заколисувати їхню увагу, замість ділової розмови перевести візит у банкет і п’янку. Усі ці радянські прихвати можна помітити ледь не в кожній поїздці президента чи прем’єра регіонами.  Якщо демократизація, яка розпочалася з часів горбачовської перебудови, змусила політиків бути більш публічними, то «червоних директорів» ця вимога часу зовсім не торкнулася. Чимало нинішніх керівників  підприємств – індустріальних монстрів часів СРСР – у своїй поведінці нагадують героя серіалу «Чорнобиль» Анатолія Дятлова, інженера ЧАЕС. Зухвалий, хамовитий, не схильний чути будь-яку думку, окрім власної – такий тип керівників виховували на так званих «закритих» підприємствах: оборонних заводах, атомних станціях тощо. Режим секретності й ласка від влади дозволяли поводитися з підлеглими саме так, як Дятлов. У сучасній Україні чимало таких директорів залишилося у південно-східних регіонах. Усі ці «міцні господарники», які на догоду своїм політичним партнерам з Партії регіонів завжди могли організувати кілька автобусів з робітниками – для Антимайдану чи якоїсь подібної акції. Великі металургійні, хімічні, машинобудівні підприємства залишаються потенційними «чорнобилями». Не в останню чергу – через керівників старої формації. Про складну екологічну ситуацію в Маріуполі писали дуже багато разів. Але, як не дивно, серед місцевих, особливо працівників ахметовських меткомбінтаів, найпоширенішим є настрій: «Так, викиди вбивають довкілля, але ж ці заводи дають нам роботу – то чи є сенс щось змінювати»? Люди озвучують позицію керівництва, не сміють йти проти неї. Так само, як молоді співробітники ЧАЕС у серіалі.  Навіть у комерційних фірмах таких некомпетентних самодурів немало. Як свідчать соцопитування конфлікти з керівництвом входить в ТОП-3 причин звільнення звільнення з роботи. Керівники навіть несвідомо копіюють цю радянську модель. По київських редакціях ходить легенда про редактора, який так само кричав і принижував підлеглих, як і Дятлов.   Хамство в розмовах звичне і для першого кабінету країни. Записи директора Кучми всі чули; Ющенко, попри інтелігентний вигляд, дозволяв собі на людях звертатися до незнайомих чиновників на «ти», кричати на них; про  Януковича кажуть, що міг і в морду дати (але доказів немає); за свідченнями оточення Порошенка, він теж досить зверхньо і зневажливо міг говорити зі своїми підлеглими та політичними партнерами. Реального Зеленського ми побачили під час першої спроби Радіо «Свобода» взяти в нього інтерв’ю. Потім цей нахабний і зневажливий стиль спілкування перейшов у відеозвернення.  Що там президенти! Подивіться, як говорять вчителі з дітьми у школах чи батьки на дитячих майданчиках. Таких «дятлових» сотні тисяч, і вони передають свою культуру (в розумінні набору навичок спілкування, звичок, світогляду тощо) наступним поколінням. Мабуть скрізь у світі є люди, які нехтують посадовими інструкціями з безпека. Але в Союзі це увійло в культ. Сцена в останній серії, коли працівник апаратної кричить, що цього робити не можна, але начальник каже \"Робіть!\" західним глядачем сприймається, мабуть, як виняткове самодурство. Та ми втаємничені і знаємо, що нехтування безпекою загальне правило на наших теренах. Крайнім і абсурдним проявом цього культурного феномену є відмова частини водіїв пристібатися пасками безпеки.  Чорнобиль породив не лише недовіру до чиновників, а й до техніки. Вагома частина серіалу присвячена пошуку причин аварії на ЧАЕС, і одна з них – дефект радянських атомних реакторів. Визнати це перед усім світом, з точки зору радянського керівництва, було неприпустимо – і навіть всередині країни говорити про це є зухвалим злочином. В українцях відтоді живе переконаність, що будь-яка техніка вітчизняного виробництва – неякісна і небезпечна для життя. З останніх прикладів – міномети «Молот»: чимало фахівців говорить про те, що фатальні вибухи під час стрільб найчастіше трапляються через помилки розрахунків (подвійне заряджання, наприклад). Проте, дуже популярним є настрій «це українські міномети такі неякісні».  Те саме стосується й цивільних сфер життя: австралійці можуть радісно зустрічати українську «Мрію». Українці ж воліють здебільшого не помічати жодних технологічних розробок на Батьківщині: дається взнаки скепсис, народжений в роки перебудов. Частково він породжений об’єктивно вищою якістю багатьох західних товарів, частково – розчаруваннями в радянському «науково-технічному прогресі», який обернувся страхітливою техногенною аварією. у фільмі присутня суб’єктність колонії Україна Фільмові інколи закидають: Україна в ньому, мовляв, як справжня колонія, позбавлена суб’єктності. Докір не зовсім справедливий. По-перше, станом на 1986-ий рік УРСР дійсно була позбавлена суб’єктності. По-друге, у фільмі присутня суб’єктність колонії. Один із сильних моментів фільму: діалог солдата й бабці, що не збирається залишати свою оселю та згадує усі трагедії, які пережила Україна в ХХ столітті. У цій бабусі легко вгадати нинішніх мешканців прифронтових сіл на Донбасі, які, хай там що, не збираються покидати свої помешкання. Укоріненість – це те, що не змінюється з роками. Війна – єдиний порівнюваний з Чорнобилем шок, який Україна пережила у новітній історії. І тоді, і тепер все значною мірою трималося на людях із розвиненим почуттям обов’язку: вчених, військових, добровольцях. Вони можуть входити у конфлікт із владою, не знати реального масштабу загроз, але виконувати свою справу під десантним гаслом «ніхто крім нас». З одним відчутним «але»: примусу в Україні значно менше, і ризикують життям ті, хто морально готовий для цього.\n"
     ]
    }
   ],
   "source": [
    "example_article = articles.article[1]\n",
    "example_title = articles.title[1]\n",
    "\n",
    "print(\"Title: \" + example_title)\n",
    "print(\"Article: \" + example_article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.uk.stop_words import STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C_7BtlGGZ2Af"
   },
   "outputs": [],
   "source": [
    "def clean_text(text, remove_stopwords = True):\n",
    "    '''Remove unwanted characters, stopwords, and format the text to create fewer nulls word embeddings'''\n",
    "    \n",
    "    # Convert words to lower case\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Format words and remove unwanted characters\n",
    "    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'\\<a href', ' ', text)\n",
    "    text = re.sub(r'&amp;', '', text) \n",
    "    text = re.sub(r'[_\"\\-;%()|+&=*%.,!?:#$@\\[\\]/]', ' ', text)\n",
    "    text = re.sub(r'<br />', ' ', text)\n",
    "    text = re.sub(r'\\'', ' ', text)\n",
    "    pattern = re.compile('[\\W_]+')\n",
    "    text = pattern.sub(' ', text)\n",
    "    \n",
    "    # Optionally, remove stop words\n",
    "    if remove_stopwords:\n",
    "        text = text.split()\n",
    "        stops = STOP_WORDS\n",
    "        text = [w for w in text if not w in stops]\n",
    "        text = \" \".join(text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'влада погано комунікує суспільством чуємо явища причин одна криється чорнобильській трагедії аварію причини наслідки попервах погано розуміли кремлі усіляко приховували применшували власне срср доброю традицією чаес першою техногенною катастрофою варто задати киштимську аварію уралі 1957 го масштаб інформаційний ефект чорнобиля нечуваний відтоді серед українців залишилася помітна травма трапляється надзвичайне влада вочевидь брехатиме викривлятиме інформацію соціумі велике поле чуток маніпуляцій добу соцмереж являються фейкові повідомлення стилі чоловік подруги працює пожежником чорнобильські зоні йдуть різні варіації жахалок заходить 30 вибуху аес надто цинічною брехня брехатимуть впевнені мільйони громадян незалежній україні тотальної цензури всемогутнього кгб імперських амбіцій чиновникам надзвичайних ситуацій доводиться докладати чимало зусиль викликати бодай якусь довіру порівняно недавня історія 2007 го села ожидів львівщині перекинулися цистерни фосфором генерал олександр кузьмук віце прем єром приїхав місце подій заспокоїти місцевих мешканців скуштував огірок городу місцевої мешканки погляд типова ляшковщина пережиток чорнобиля однойменному серіалі промовиста сцена шахтар кидає стіл московськими чиновниками респіратор словами якби респіратори допомагали носили знімаючи чорнобильська брехня породила недовіру представники влади змушені переконувати людей власним емпіричним прикладом бодай персональною присутністю торік масове отруєння дітей черкасах володимир гройсман особисто літав провідати люди молодшого покоління висміяли численних фотожабах покоління яке пережило чорнобиль особиста присутність очільника уряду стала переконливим спростуванням неймовірних чуток екологічну ситуацію місті серіалі доволі промовисто показано ієрархію радянського чиновництва дрібні місцеві функціонери прагнуть обдурити столичних шишок уникнути відповідальності зіграти некомпетентності високих гостей прип ятські можновладці зустрічають бориса щербину впевнені зуміють навіщати локшини вуха кремлівському партійному бонзі їхньому здивуванню меж товариш цк демонструє знання атомної енергетики українськими чиновниками візитерам києва прагнуть продемонструвати показуху пускати фасаду заколисувати їхню увагу замість ділової розмови перевести візит банкет п янку радянські прихвати помітити ледь кожній поїздці президента прем єра регіонами демократизація розпочалася часів горбачовської перебудови змусила політиків публічними червоних директорів вимога торкнулася чимало нинішніх керівників підприємств індустріальних монстрів часів срср поведінці нагадують героя серіалу чорнобиль анатолія дятлова інженера чаес зухвалий хамовитий схильний чути яку думку власної тип керівників виховували званих закритих підприємствах оборонних заводах атомних станціях тощо режим секретності влади дозволяли поводитися підлеглими дятлов сучасній україні чимало таких директорів залишилося південно східних регіонах міцні господарники догоду своїм політичним партнерам партії регіонів могли організувати автобусів робітниками антимайдану якоїсь подібної акції великі металургійні хімічні машинобудівні підприємства залишаються потенційними чорнобилями останню чергу керівників старої формації складну екологічну ситуацію маріуполі писали разів дивно серед місцевих працівників ахметовських меткомбінтаів найпоширенішим настрій викиди вбивають довкілля заводи дають роботу сенс змінювати люди озвучують позицію керівництва сміють йти молоді співробітники чаес серіалі комерційних фірмах таких некомпетентних самодурів немало свідчать соцопитування конфлікти керівництвом входить топ 3 причин звільнення звільнення роботи керівники несвідомо копіюють радянську модель київських редакціях ходить легенда редактора кричав принижував підлеглих дятлов хамство розмовах звичне першого кабінету країни записи директора кучми чули ющенко попри інтелігентний вигляд дозволяв людях звертатися незнайомих чиновників кричати януковича кажуть морду дати доказів свідченнями оточення порошенка зверхньо зневажливо говорити своїми підлеглими політичними партнерами реального зеленського побачили першої спроби радіо свобода взяти інтерв ю нахабний зневажливий стиль спілкування перейшов відеозвернення президенти подивіться говорять вчителі дітьми школах батьки дитячих майданчиках таких дятлових сотні передають культуру розумінні набору навичок спілкування звичок світогляду тощо наступним поколінням мабуть світі люди нехтують посадовими інструкціями безпека союзі увійло культ сцена останній серії працівник апаратної кричить робити начальник робіть західним глядачем сприймається мабуть виняткове самодурство втаємничені знаємо нехтування безпекою загальне правило теренах крайнім абсурдним проявом культурного феномену відмова частини водіїв пристібатися пасками безпеки чорнобиль породив недовіру чиновників техніки вагома частина серіалу присвячена пошуку причин аварії чаес одна дефект радянських атомних реакторів визнати світом точки зору радянського керівництва неприпустимо всередині країни говорити зухвалим злочином українцях відтоді живе переконаність техніка вітчизняного виробництва неякісна небезпечна життя останніх прикладів міномети молот чимало фахівців фатальні вибухи стрільб найчастіше трапляються помилки розрахунків подвійне заряджання наприклад популярним настрій українські міномети неякісні стосується цивільних сфер життя австралійці радісно зустрічати українську мрію українці воліють здебільшого помічати жодних технологічних розробок батьківщині дається взнаки скепсис народжений перебудов частково породжений об єктивно вищою якістю багатьох західних товарів частково розчаруваннями радянському науково технічному прогресі обернувся страхітливою техногенною аварією фільмі присутня суб єктність колонії україна фільмові інколи закидають україна мовляв справжня колонія позбавлена суб єктності докір справедливий перше станом 1986 ий урср позбавлена суб єктності друге фільмі присутня суб єктність колонії сильних моментів фільму діалог солдата бабці збирається залишати оселю згадує трагедії пережила україна хх столітті бабусі легко вгадати нинішніх мешканців прифронтових сіл донбасі хай збираються покидати помешкання укоріненість змінюється роками війна єдиний порівнюваний чорнобилем шок україна пережила новітній історії значною мірою трималося людях розвиненим почуттям обов язку вчених військових добровольцях входити конфлікт владою знати реального масштабу загроз виконувати справу десантним гаслом ніхто одним відчутним примусу україні значно ризикують життям морально готовий'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text(example_article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "MZg_8goOZ4yy",
    "outputId": "dd020f11-5081-4521-d663-b86ece4e7d12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summaries are complete.\n",
      "Texts are complete.\n"
     ]
    }
   ],
   "source": [
    "# Clean the summaries and texts\n",
    "clean_summaries = []\n",
    "for summary in articles.title:\n",
    "    clean_summaries.append(clean_text(summary, remove_stopwords=False))\n",
    "print(\"Summaries are complete.\")\n",
    "\n",
    "clean_texts = []\n",
    "for text in articles.article:\n",
    "    clean_texts.append(clean_text(text))\n",
    "print(\"Texts are complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 384
    },
    "colab_type": "code",
    "id": "t1MO5QwNZ62b",
    "outputId": "1a8627f0-4dec-4d1b-c555-8a57c453742d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 хвилин на реакцію як ефективно протидіяти дезінформації не запроваджуючи цензуру досвід тайваню\n",
      "\n",
      "одрі танг любить висловлюватися точно інтерв ю тайванський міністр портфеля табличці іменем танга написано цифровий міністр негайно виправляє згадуємо термін фейкові новини прийнятний термін дезінформація танг юридичне поняття тайвані тобто навмисна спрямована шкоду неправда найважливіше шкодить громадськості демократичній системі образу міністра сміхом шкодити міністру звичайна якісна журналістика відміну владних режимів азії таких сингапур тайвань вирішив боротися пошестю дезінформації вдаючись цензури арештів тайвань вийшов воєнного стану 1987 провів перші президентські вибори 1996 му попри економіка тайваню суттєво залежить торгівлі інвестицій китаю вважає тайвань своєю територією демократія продовжувала відокремлювати політичної системи континенті виборці тайваню обирають партією гоміндан схильна тісніших стосунків китаєм демократичною прогресивною партією дпп наголошує автономії прямій незалежності китаю чинна президентка цай інвень належить дпп танг програмістка вийшла хакерського середовища минулого тижня зустрілася журналістом комітету захисту журналістів тайпеї мета поспілкуватися тайвань намагається зберегти чесність демократичність змі противагу своєму значно більшому опоненту китаю жорстко контролює власні медіа потенційну змогу посіяти хаос відкритій медійній системі тайваню вважаю тайвані найбільшою мірою покладаємося власну здатність суспільства виявляти дезінформацію тобто навмисну спрямовану завдання шкоди неправду противагу журналістській роботі легко тридцять тридцять п ять тайвань перебуває китайська народна республіка людей старше покоління мають труднощі розрізненням дезінформації справжньої журналістської роботи державні змі єдиними змі відверто кажучи чимало пропаганди тож відмінності побачити людей народилися здобували освіту скасування воєнного стану тобто 80 х широкий діапазон інформаційних джерел їхній вибір демократія розпочалася перших президентських виборів 1996 му збіглася часі появою world wide web тож люди пов язують демократію демократизацією джерел інформації дезінформація небезпека відкритих суспільств тайваню режимів кнр використовують дезінформацію привід держави запровадити цензуру хочемо йти шляхом пам ятаємо воєнний стан перше масового поширення пропагандистської дезінформаційної кампанії спостерігаємо появу відправної точки здійснюють певне тестування перевірку різних варіантів стануть справді популярними тестуються меми різні версії побачити отримають вірусне поширення міністерств команду відповідальну разі виявлення дезінформаційної кампанії сягнула мас протягом 60 хвилин виготовити переконливе повідомлення короткий фільм картка медіа допис соціальних мережах міністр робить стрім президент прийшла комедійне шоу прем єр міністр дивиться стрім відеогри виявили робимо більшість населення отримує повідомлення щеплення дійде дезінформація тож захист працює подібно вакцини ведемо зразок таблиці обліку визначаємо міністерству реагування міністерству внутрішніх середньому 60 хвилин міністерству здоров добробуту середньому 70 змагаються своєрідній дружній конкуренції реагують швидше швидше вийдуть 60 хвилинну межу передають меседжі платформу миттєвих повідомлень line facebook екаунти президента цай інвень прем єра віце прем єра кожний велику кількість підписників суті просять фоловерів поширити роз яснення надійшло їхніх друзів родичів повідомлення дезінформацією традиційні змі звісно отримують контрповідомлення завдяки готують збалансовані публікації побачили випадку запустили контрповідомлення приготували відеоролики фільми картинки годин починається новий цикл новин змі протидія безнадійна чесно кажучи насправді виснажує деякі стають вірусними непомітно відбувається каналах застосовують наскрізне шифрування відміну фейсбук твіттер систем працює індексація гугл канали недоступні пошукових механізмів закрита кімната легко провести мутацію дезінформації потужний мем перш випустять мовити світ широкий розробили співпраці соціальною мережею line facebook систему яку називаємо сповіщення громадське сповіщення система працює подібно спам фільтра отримали електронний лист думаєте спам сміттєва реклама теоретично приватні комунікації держава переглядати пошту думаєте лист надійшов якоїсь країни принцеса хоче поділитися п ятьма мільйонами доларів можете позначити лист спам двохтисячних інтернет спільнота переконали операторів електронної пошти додати таку кнопку інтерфейсу ставили помітку спам пересилали текст повідомлення обов язково добровільне пожертвування глобальній системі назвою spamhaus список блокування доменів тощо існує ціла система імунна система електронної пошти значна кількість людей ставить прапорець спам робить кореляцію відправником листа відправляє наступного листа доходить адресата цензури нема потрапляє папки сміттєвою поштою замовчанням відбирати людей розробляємо схожу систему люди пересилати онлайнову інформацію повідомлення отримані системах негайних повідомлень спеціальному боту наразі популярний бот називається cofact тобто collaborative fact колективний факт скоро червні соціальна система line вбудує функціональність зробити натиснути повідомлення можете позначити дезінформацію наприклад справді популярна чутка випадку землетрусу потужнішого балів сусідні держави надсилати команди рятувальників згоди країни постраждала землетрусу привід окупації розумієте бог знає поширювали повідомлення якому випадку популярне повідомлення тож тайванський центр фактчекінгу досліджує міжнародні угоди договори підписані міністром закордонних подібні речі цитати джерела цитат зрештою заявляє повідомлення фальшивкою зробили facebook пообіцяв червня уточнять алгоритм facebook припинив поширювати повідомлення популярне стрічці цензурою подивитеся стрічку друга повідомлення залишилося містить попередження перевірка фактів встановила неправдивість напрацьовуємо схожі домовленості іншми соціальними мережами line популярна азії система обміну миттєвими повідомленнями прим facebook долучилися впровадження системи сповіщення громадське сповіщення ніяк системою сповіщення вилучення інформації примітка редактора речник line повідомив телефоном cpj співпрацюють групами факт чекінгу такими cofact ｍygopen taiwan factcheck center rumor truth задля створення офіційного екаунту line перевірки фактів користувачі зможуть пересилати сумнівну інформацію робити запит перевірку відповідності фактам facebook відповів негайно запит електронною поштою коментар виборів діє спеціальний набір правил обмежує пожертви кампанію відповідно відзначили іноземні кошти надходять шляхом виявлено надають перевагу закупівлі точно націленої реклами соціальних мережах традиційних змі тож кажемо пожертви кампанію слід розкрити інформацію дані пожертви місцеве населення право витрачати гроші фінансувати політичну рекламу рекламне агентство посередник повинен повідомити звідки надійшли кошти боротьба відмиванням грошей кінці ланцюжка виявиться іноземець кнр макао гонконг насправді злочином вибори особливою ситуацією захищаємо виборчий процес значно вищому рівіні звичайна система повідомлень громадських повідомлень\n"
     ]
    }
   ],
   "source": [
    "# Example of cleaned article\n",
    "print(clean_summaries[0])\n",
    "print()\n",
    "print(clean_texts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count the number of occurrences of each word in a set of text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aKm8RMdya1Rh"
   },
   "outputs": [],
   "source": [
    "def count_words(count_dict, text):\n",
    "    '''Count the number of occurrences of each word in a set of text'''\n",
    "    for sentence in text:\n",
    "        for word in sentence.split():\n",
    "            if word not in count_dict:\n",
    "                count_dict[word] = 1\n",
    "            else:\n",
    "                count_dict[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ми': 1,\n",
       " 'будемо': 1,\n",
       " 'їсти': 2,\n",
       " 'піццу': 1,\n",
       " 'сьогодні': 1,\n",
       " 'ввечері': 1,\n",
       " 'овочі': 1,\n",
       " 'корисно': 1}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydict = {}\n",
    "count_words(mydict, [\"ми будемо їсти піццу сьогодні ввечері\", \"їсти овочі корисно\"])\n",
    "mydict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "RYMNdxR-a3R4",
    "outputId": "4750104a-278a-48aa-f227-2f0504ea1070"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Vocabulary: 72434\n"
     ]
    }
   ],
   "source": [
    "word_counts = {}\n",
    "\n",
    "count_words(word_counts, clean_summaries)\n",
    "count_words(word_counts, clean_texts)\n",
    "            \n",
    "print(\"Size of Vocabulary:\", len(word_counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load embeddings for Ukrainian language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Es_I5U0xa5S5",
    "outputId": "4e373d1c-da1f-4d13-cd39-9fe9dad89c4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word embeddings: 328959\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "with open('news.lowercased.tokenized.word2vec.300d') as f:\n",
    "    for line in f:\n",
    "        values = line.split(' ')\n",
    "        word = values[0]\n",
    "        embedding = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = embedding\n",
    "\n",
    "print('Word embeddings:', len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# explore e,bedding dimention\n",
    "embeddings_index[\"мама\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "AW802uiNa75r",
    "outputId": "1671d467-611c-49c2-b660-c0d30f0ff431"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words missing from Word2Vec: 4\n",
      "Percent of words that are missing from vocabulary: 0.01%\n"
     ]
    }
   ],
   "source": [
    "missing_words = 0\n",
    "threshold = 20\n",
    "\n",
    "for word, count in word_counts.items():\n",
    "    if count > threshold:\n",
    "        if word not in embeddings_index:\n",
    "            missing_words += 1\n",
    "            \n",
    "missing_ratio = round(missing_words/len(word_counts),4)*100\n",
    "            \n",
    "print(\"Number of words missing from Word2Vec:\", missing_words)\n",
    "print(\"Percent of words that are missing from vocabulary: {}%\".format(missing_ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('гриняка', 22), ('width', 24), ('font', 36), ('аннабелла', 21)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_words = []\n",
    "for word, count in word_counts.items():\n",
    "    if count > threshold and word not in embeddings_index:\n",
    "        missing_words.append((word,count))\n",
    "missing_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Words to indexes, indexes to words dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "Kmqng2XHh6_p",
    "outputId": "1db59845-6d51-4c37-f499-460c7ce4a080"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of unique words: 72434\n",
      "Number of words we will use: 61608\n",
      "Percent of words we will use: 85.05%\n"
     ]
    }
   ],
   "source": [
    "vocab_to_int = {} \n",
    "\n",
    "value = 0\n",
    "for word, count in word_counts.items():\n",
    "    if count >= threshold or word in embeddings_index:\n",
    "        vocab_to_int[word] = value\n",
    "        value += 1\n",
    "\n",
    "# Special tokens that will be added to our vocab\n",
    "codes = [\"<UNK>\",\"<PAD>\",\"<EOS>\",\"<GO>\"]   \n",
    "\n",
    "# Add codes to vocab\n",
    "for code in codes:\n",
    "    vocab_to_int[code] = len(vocab_to_int)\n",
    "\n",
    "# Dictionary to convert integers to words\n",
    "int_to_vocab = {}\n",
    "for word, value in vocab_to_int.items():\n",
    "    int_to_vocab[value] = word\n",
    "\n",
    "usage_ratio = round(len(vocab_to_int) / len(word_counts),4)*100\n",
    "\n",
    "print(\"Total number of unique words:\", len(word_counts))\n",
    "print(\"Number of words we will use:\", len(vocab_to_int))\n",
    "print(\"Percent of words we will use: {}%\".format(usage_ratio))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create word embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "rwT6WIjDh-5I",
    "outputId": "7f53a08f-8158-4681-996b-e1bdd7a2322b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61608\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 300\n",
    "nb_words = len(vocab_to_int)\n",
    "\n",
    "# Create matrix with default values of zero\n",
    "word_embedding_matrix = np.zeros((nb_words, embedding_dim), dtype=np.float32)\n",
    "for word, i in vocab_to_int.items():\n",
    "    if word in embeddings_index:\n",
    "        word_embedding_matrix[i] = embeddings_index[word]\n",
    "    else:\n",
    "        # If word not in CN, create a random embedding for it\n",
    "        new_embedding = np.array(np.random.uniform(-1.0, 1.0, embedding_dim))\n",
    "        embeddings_index[word] = new_embedding\n",
    "        word_embedding_matrix[i] = new_embedding\n",
    "\n",
    "# Check if value matches len(vocab_to_int)\n",
    "print(len(word_embedding_matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert sentences to sequence of words indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2gobgfFZiCHR"
   },
   "outputs": [],
   "source": [
    "def convert_to_ints(text, word_count, unk_count, eos=False):\n",
    "    '''Convert words in text to an integer.\n",
    "       If word is not in vocab_to_int, use UNK's integer.\n",
    "       Total the number of words and UNKs.\n",
    "       Add EOS token to the end of texts'''\n",
    "    ints = []\n",
    "    for sentence in text:\n",
    "        sentence_ints = []\n",
    "        for word in sentence.split():\n",
    "            word_count += 1\n",
    "            if word in vocab_to_int:\n",
    "                sentence_ints.append(vocab_to_int[word])\n",
    "            else:\n",
    "                sentence_ints.append(vocab_to_int[\"<UNK>\"])\n",
    "                unk_count += 1\n",
    "        if eos:\n",
    "            sentence_ints.append(vocab_to_int[\"<EOS>\"])\n",
    "        ints.append(sentence_ints)\n",
    "    return ints, word_count, unk_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "uHOLyENmiFmo",
    "outputId": "cb410300-aff9-4ea9-a07f-746a2dc5a8b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words in headlines: 319145\n",
      "Total number of UNKs in headlines: 13677\n",
      "Percent of words that are UNK: 4.29%\n"
     ]
    }
   ],
   "source": [
    "word_count = 0\n",
    "unk_count = 0\n",
    "\n",
    "int_summaries, word_count, unk_count = convert_to_ints(clean_summaries, word_count, unk_count)\n",
    "int_texts, word_count, unk_count = convert_to_ints(clean_texts, word_count, unk_count, eos=True)\n",
    "\n",
    "unk_percent = round(unk_count/word_count,4)*100\n",
    "\n",
    "print(\"Total number of words in headlines:\", word_count)\n",
    "print(\"Total number of UNKs in headlines:\", unk_count)\n",
    "print(\"Percent of words that are UNK: {}%\".format(unk_percent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12],\n",
       " [13, 14, 15, 61604, 16, 17, 18, 19, 20, 21, 22, 23, 24],\n",
       " [25, 26, 61604, 27, 28, 29, 30, 31, 32, 33, 34],\n",
       " [35, 36, 37, 4, 38, 39, 40, 41, 42, 43, 44, 8, 45, 46, 47],\n",
       " [48, 49, 50, 51, 52, 4, 53, 54, 55, 56, 57, 23, 58],\n",
       " [59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70],\n",
       " [71, 72, 23, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 20],\n",
       " [86, 87, 88, 89, 90, 91, 92, 93, 94, 2, 61604],\n",
       " [61604, 95, 96, 97, 98, 61604, 99, 100, 14, 101, 102, 103]]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_summaries[:9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the length of each sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2OD95WMaiIVK"
   },
   "outputs": [],
   "source": [
    "def create_lengths(text):\n",
    "    '''Create a data frame of the sentence lengths from a text'''\n",
    "    lengths = []\n",
    "    for sentence in text:\n",
    "        lengths.append(len(sentence))\n",
    "    return pd.DataFrame(lengths, columns=['counts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   counts\n",
       "0      13\n",
       "1      13\n",
       "2      11"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_lengths(int_summaries[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381
    },
    "colab_type": "code",
    "id": "IBDnDWjfiMXu",
    "outputId": "290137d6-0375-42d0-92f0-1234860d73ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summaries:\n",
      "           counts\n",
      "count  469.000000\n",
      "mean    12.347548\n",
      "std      3.169145\n",
      "min      5.000000\n",
      "25%     10.000000\n",
      "50%     12.000000\n",
      "75%     14.000000\n",
      "max     25.000000\n",
      "\n",
      "Texts:\n",
      "            counts\n",
      "count   469.000000\n",
      "mean    669.132196\n",
      "std     550.680181\n",
      "min       4.000000\n",
      "25%     217.000000\n",
      "50%     567.000000\n",
      "75%     994.000000\n",
      "max    2897.000000\n"
     ]
    }
   ],
   "source": [
    "lengths_summaries = create_lengths(int_summaries)\n",
    "lengths_texts = create_lengths(int_texts)\n",
    "\n",
    "print(\"Summaries:\")\n",
    "print(lengths_summaries.describe())\n",
    "print()\n",
    "print(\"Texts:\")\n",
    "print(lengths_texts.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1322.1599999999999\n",
      "1690.2\n",
      "2388.96\n"
     ]
    }
   ],
   "source": [
    "# Inspect the length of texts\n",
    "print(np.percentile(lengths_texts.counts, 89.5))\n",
    "print(np.percentile(lengths_texts.counts, 95))\n",
    "print(np.percentile(lengths_texts.counts, 99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.19999999999999\n",
      "17.0\n",
      "21.0\n"
     ]
    }
   ],
   "source": [
    "# Inspect the length of summaries\n",
    "print(np.percentile(lengths_summaries.counts, 90))\n",
    "print(np.percentile(lengths_summaries.counts, 95))\n",
    "print(np.percentile(lengths_summaries.counts, 99))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count the number of time UNKNOWN appears in a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9ftG9iqtiRhC"
   },
   "outputs": [],
   "source": [
    "def unk_counter(sentence):\n",
    "    '''Counts the number of time UNK appears in a sentence.'''\n",
    "    unk_count = 0\n",
    "    for word in sentence:\n",
    "        if word == vocab_to_int[\"<UNK>\"]:\n",
    "            unk_count += 1\n",
    "    return unk_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254\n",
      "254\n"
     ]
    }
   ],
   "source": [
    "max_text_length = 2000 # This will cover up to 89.5% lengthes\n",
    "max_summary_length = 20 # This will cover up to 99% lengthes\n",
    "min_length = 2\n",
    "unk_text_limit = 20 # text can contain up to 1 UNK word\n",
    "unk_summary_limit = 5 # Summary should not contain any UNK word\n",
    "\n",
    "def filter_condition(item):\n",
    "    int_summary = item[0]\n",
    "    int_text = item[1]\n",
    "    if(len(int_summary) >= min_length and \n",
    "       len(int_summary) <= max_summary_length and \n",
    "       len(int_text) >= min_length and \n",
    "       len(int_text) <= max_text_length and \n",
    "       unk_counter(int_summary) <= unk_summary_limit and \n",
    "       unk_counter(int_text) <= unk_text_limit):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "int_text_summaries = list(zip(int_summaries , int_texts))\n",
    "int_text_summaries_filtered = list(filter(filter_condition, int_text_summaries))\n",
    "sorted_int_text_summaries = sorted(int_text_summaries_filtered, key=lambda item: len(item[1]))\n",
    "sorted_int_text_summaries = list(zip(*sorted_int_text_summaries))\n",
    "sorted_summaries = list(sorted_int_text_summaries[0])\n",
    "sorted_texts = list(sorted_int_text_summaries[1])\n",
    "# Delete those temporary varaibles\n",
    "del int_text_summaries, sorted_int_text_summaries, int_text_summaries_filtered\n",
    "# Compare lengths to ensure they match\n",
    "print(len(sorted_summaries))\n",
    "print(len(sorted_texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-JU3DbUGibgt"
   },
   "outputs": [],
   "source": [
    "def model_inputs():\n",
    "    '''Create palceholders for inputs to the model'''\n",
    "    \n",
    "    input_data = tf.placeholder(tf.int32, [None, None], name='input')\n",
    "    targets = tf.placeholder(tf.int32, [None, None], name='targets')\n",
    "    lr = tf.placeholder(tf.float32, name='learning_rate')\n",
    "    keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "    summary_length = tf.placeholder(tf.int32, (None,), name='summary_length')\n",
    "    max_summary_length = tf.reduce_max(summary_length, name='max_dec_len')\n",
    "    text_length = tf.placeholder(tf.int32, (None,), name='text_length')\n",
    "\n",
    "    return input_data, targets, lr, keep_prob, summary_length, max_summary_length, text_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E75uw3LQirgX"
   },
   "outputs": [],
   "source": [
    "def process_encoding_input(target_data, vocab_to_int, batch_size):\n",
    "    '''Remove the last word id from each batch and concat the <GO> to the begining of each batch'''\n",
    "    \n",
    "    ending = tf.strided_slice(target_data, [0, 0], [batch_size, -1], [1, 1])\n",
    "    dec_input = tf.concat([tf.fill([batch_size, 1], vocab_to_int['<GO>']), ending], 1)\n",
    "\n",
    "    return dec_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RRmHqVSCiujL"
   },
   "outputs": [],
   "source": [
    "def encoding_layer(rnn_size, sequence_length, num_layers, rnn_inputs, keep_prob):\n",
    "    '''Create the encoding layer'''\n",
    "    \n",
    "    for layer in range(num_layers):\n",
    "        with tf.variable_scope('encoder_{}'.format(layer)):\n",
    "            cell_fw = tf.contrib.rnn.LSTMCell(rnn_size,\n",
    "                                              initializer=tf.random_uniform_initializer(-0.1, 0.1, seed=2))\n",
    "            cell_fw = tf.contrib.rnn.DropoutWrapper(cell_fw, \n",
    "                                                    input_keep_prob = keep_prob)\n",
    "\n",
    "            cell_bw = tf.contrib.rnn.LSTMCell(rnn_size,\n",
    "                                              initializer=tf.random_uniform_initializer(-0.1, 0.1, seed=2))\n",
    "            cell_bw = tf.contrib.rnn.DropoutWrapper(cell_bw, \n",
    "                                                    input_keep_prob = keep_prob)\n",
    "\n",
    "            enc_output, enc_state = tf.nn.bidirectional_dynamic_rnn(cell_fw, \n",
    "                                                                    cell_bw, \n",
    "                                                                    rnn_inputs,\n",
    "                                                                    sequence_length,\n",
    "                                                                    dtype=tf.float32)\n",
    "    # Join outputs since we are using a bidirectional RNN\n",
    "    enc_output = tf.concat(enc_output,2)\n",
    "    \n",
    "    return enc_output, enc_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o312UorKiyhE"
   },
   "outputs": [],
   "source": [
    "def training_decoding_layer(dec_embed_input, summary_length, dec_cell, initial_state, output_layer, \n",
    "                            vocab_size, max_summary_length):\n",
    "    '''Create the training logits'''\n",
    "    \n",
    "    training_helper = tf.contrib.seq2seq.TrainingHelper(inputs=dec_embed_input,\n",
    "                                                        sequence_length=summary_length,\n",
    "                                                        time_major=False)\n",
    "\n",
    "    training_decoder = tf.contrib.seq2seq.BasicDecoder(dec_cell,\n",
    "                                                       training_helper,\n",
    "                                                       initial_state,\n",
    "                                                       output_layer) \n",
    "\n",
    "    training_logits, _ , _ = tf.contrib.seq2seq.dynamic_decode(training_decoder,\n",
    "                                                           output_time_major=False,\n",
    "                                                           impute_finished=True,\n",
    "                                                           maximum_iterations=max_summary_length)\n",
    "    return training_decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lJfDRX6yi1dD"
   },
   "outputs": [],
   "source": [
    "def inference_decoding_layer(embeddings, start_token, end_token, dec_cell, initial_state, output_layer,\n",
    "                             max_summary_length, batch_size):\n",
    "    '''Create the inference logits'''\n",
    "    \n",
    "    start_tokens = tf.tile(tf.constant([start_token], dtype=tf.int32), [batch_size], name='start_tokens')\n",
    "    \n",
    "    inference_helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(embeddings,\n",
    "                                                                start_tokens,\n",
    "                                                                end_token)\n",
    "                \n",
    "    inference_decoder = tf.contrib.seq2seq.BasicDecoder(dec_cell,\n",
    "                                                        inference_helper,\n",
    "                                                        initial_state,\n",
    "                                                        output_layer)\n",
    "                \n",
    "    inference_logits, _ , _ = tf.contrib.seq2seq.dynamic_decode(inference_decoder,\n",
    "                                                            output_time_major=False,\n",
    "                                                            impute_finished=True,\n",
    "                                                            maximum_iterations=max_summary_length)\n",
    "    \n",
    "    return inference_decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bPQ4wxdyi37i"
   },
   "outputs": [],
   "source": [
    "def decoding_layer(dec_embed_input, embeddings, enc_output, enc_state, vocab_size, text_length, summary_length, \n",
    "                   max_summary_length, rnn_size, vocab_to_int, keep_prob, batch_size, num_layers):\n",
    "    '''Create the decoding cell and attention for the training and inference decoding layers'''\n",
    "    \n",
    "    for layer in range(num_layers):\n",
    "        with tf.variable_scope('decoder_{}'.format(layer)):\n",
    "            lstm = tf.contrib.rnn.LSTMCell(rnn_size,\n",
    "                                           initializer=tf.random_uniform_initializer(-0.1, 0.1, seed=2))\n",
    "            dec_cell = tf.contrib.rnn.DropoutWrapper(lstm, \n",
    "                                                     input_keep_prob = keep_prob)\n",
    "    \n",
    "    output_layer = Dense(vocab_size,\n",
    "                         kernel_initializer = tf.truncated_normal_initializer(mean = 0.0, stddev=0.1))\n",
    "    \n",
    "    attn_mech = tf.contrib.seq2seq.BahdanauAttention(rnn_size,\n",
    "                                                  enc_output,\n",
    "                                                  text_length,\n",
    "                                                  normalize=False,\n",
    "                                                  name='BahdanauAttention')\n",
    "\n",
    "    dec_cell = tf.contrib.seq2seq.AttentionWrapper(dec_cell,\n",
    "                                                          attn_mech,\n",
    "                                                          rnn_size)\n",
    "            \n",
    "    #initial_state = tf.contrib.seq2seq.AttentionWrapperState(enc_state[0],\n",
    "    #                                                                _zero_state_tensors(rnn_size, \n",
    "    #                                                                                    batch_size, \n",
    "    #                                                                                    tf.float32)) \n",
    "    initial_state = dec_cell.zero_state(batch_size=batch_size,dtype=tf.float32).clone(cell_state=enc_state[0])\n",
    "\n",
    "    with tf.variable_scope(\"decode\"):\n",
    "        training_decoder = training_decoding_layer(dec_embed_input, \n",
    "                                                  summary_length, \n",
    "                                                  dec_cell, \n",
    "                                                  initial_state,\n",
    "                                                  output_layer,\n",
    "                                                  vocab_size, \n",
    "                                                  max_summary_length)\n",
    "        \n",
    "        training_logits,_ ,_ = tf.contrib.seq2seq.dynamic_decode(training_decoder,\n",
    "                                  output_time_major=False,\n",
    "                                  impute_finished=True,\n",
    "                                  maximum_iterations=max_summary_length)\n",
    "    with tf.variable_scope(\"decode\", reuse=True):\n",
    "        inference_decoder = inference_decoding_layer(embeddings,  \n",
    "                                                    vocab_to_int['<GO>'], \n",
    "                                                    vocab_to_int['<EOS>'],\n",
    "                                                    dec_cell, \n",
    "                                                    initial_state, \n",
    "                                                    output_layer,\n",
    "                                                    max_summary_length,\n",
    "                                                    batch_size)\n",
    "        \n",
    "        inference_logits,_ ,_ = tf.contrib.seq2seq.dynamic_decode(inference_decoder,\n",
    "                                  output_time_major=False,\n",
    "                                  impute_finished=True,\n",
    "                                  maximum_iterations=max_summary_length)\n",
    "\n",
    "    return training_logits, inference_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "orftVP-AjqNF"
   },
   "outputs": [],
   "source": [
    "def seq2seq_model(input_data, target_data, keep_prob, text_length, summary_length, max_summary_length, \n",
    "                  vocab_size, rnn_size, num_layers, vocab_to_int, batch_size):\n",
    "    '''Use the previous functions to create the training and inference logits'''\n",
    "    \n",
    "    # Use Numberbatch's embeddings and the newly created ones as our embeddings\n",
    "    embeddings = word_embedding_matrix\n",
    "    \n",
    "    enc_embed_input = tf.nn.embedding_lookup(embeddings, input_data)\n",
    "    enc_output, enc_state = encoding_layer(rnn_size, text_length, num_layers, enc_embed_input, keep_prob)\n",
    "    \n",
    "    dec_input = process_encoding_input(target_data, vocab_to_int, batch_size)\n",
    "    dec_embed_input = tf.nn.embedding_lookup(embeddings, dec_input)\n",
    "    \n",
    "    training_logits, inference_logits  = decoding_layer(dec_embed_input, \n",
    "                                                        embeddings,\n",
    "                                                        enc_output,\n",
    "                                                        enc_state, \n",
    "                                                        vocab_size, \n",
    "                                                        text_length, \n",
    "                                                        summary_length, \n",
    "                                                        max_summary_length,\n",
    "                                                        rnn_size, \n",
    "                                                        vocab_to_int, \n",
    "                                                        keep_prob, \n",
    "                                                        batch_size,\n",
    "                                                        num_layers)\n",
    "    \n",
    "    return training_logits, inference_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xXDlzjChjwan"
   },
   "outputs": [],
   "source": [
    "def pad_sentence_batch(sentence_batch):\n",
    "    \"\"\"Pad sentences with <PAD> so that each sentence of a batch has the same length\"\"\"\n",
    "    max_sentence = max([len(sentence) for sentence in sentence_batch])\n",
    "    return [sentence + [vocab_to_int['<PAD>']] * (max_sentence - len(sentence)) for sentence in sentence_batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6HHWN1-Ojyzd"
   },
   "outputs": [],
   "source": [
    "def get_batches(summaries, texts, batch_size):\n",
    "    \"\"\"Batch summaries, texts, and the lengths of their sentences together\"\"\"\n",
    "    for batch_i in range(0, len(texts)//batch_size):\n",
    "        start_i = batch_i * batch_size\n",
    "        summaries_batch = summaries[start_i:start_i + batch_size]\n",
    "        texts_batch = texts[start_i:start_i + batch_size]\n",
    "        pad_summaries_batch = np.array(pad_sentence_batch(summaries_batch))\n",
    "        pad_texts_batch = np.array(pad_sentence_batch(texts_batch))\n",
    "        \n",
    "        # Need the lengths for the _lengths parameters\n",
    "        pad_summaries_lengths = []\n",
    "        for summary in pad_summaries_batch:\n",
    "            pad_summaries_lengths.append(len(summary))\n",
    "        \n",
    "        pad_texts_lengths = []\n",
    "        for text in pad_texts_batch:\n",
    "            pad_texts_lengths.append(len(text))\n",
    "        \n",
    "        yield pad_summaries_batch, pad_texts_batch, pad_summaries_lengths, pad_texts_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NGYG2IOfj10V"
   },
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "batch_size = 64\n",
    "rnn_size = 256\n",
    "num_layers = 2\n",
    "learning_rate = 0.005\n",
    "keep_probability = 0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "colab_type": "code",
    "id": "uxuqzSkzj6yG",
    "outputId": "8c047a66-6d54-47d6-f164-6bb5fc097e2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/vika/python-environments/env/lib/python3.6/site-packages/tensorflow/python/ops/embedding_ops.py:132: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-68-9390cb26606a>:7: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-68-9390cb26606a>:20: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /home/vika/python-environments/env/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py:443: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /home/vika/python-environments/env/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py:626: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/vika/python-environments/env/lib/python3.6/site-packages/tensorflow/python/ops/rnn_cell_impl.py:1259: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Graph is built.\n"
     ]
    }
   ],
   "source": [
    "# Build the graph\n",
    "train_graph = tf.Graph()\n",
    "# Set the graph to default to ensure that it is ready for training\n",
    "with train_graph.as_default():\n",
    "    \n",
    "    # Load the model inputs    \n",
    "    input_data, targets, lr, keep_prob, summary_length, max_summary_length, text_length = model_inputs()\n",
    "\n",
    "    # Create the training and inference logits\n",
    "    training_logits, inference_logits = seq2seq_model(tf.reverse(input_data, [-1]),\n",
    "                                                      targets, \n",
    "                                                      keep_prob,   \n",
    "                                                      text_length,\n",
    "                                                      summary_length,\n",
    "                                                      max_summary_length,\n",
    "                                                      len(vocab_to_int)+1,\n",
    "                                                      rnn_size, \n",
    "                                                      num_layers, \n",
    "                                                      vocab_to_int,\n",
    "                                                      batch_size)\n",
    "    \n",
    "    # Create tensors for the training logits and inference logits\n",
    "    training_logits = tf.identity(training_logits.rnn_output, 'logits')\n",
    "    inference_logits = tf.identity(inference_logits.sample_id, name='predictions')\n",
    "    \n",
    "    # Create the weights for sequence_loss\n",
    "    masks = tf.sequence_mask(summary_length, max_summary_length, dtype=tf.float32, name='masks')\n",
    "\n",
    "    with tf.name_scope(\"optimization\"):\n",
    "        # Loss function\n",
    "        cost = tf.contrib.seq2seq.sequence_loss(\n",
    "            training_logits,\n",
    "            targets,\n",
    "            masks)\n",
    "\n",
    "        # Optimizer\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "\n",
    "        # Gradient Clipping\n",
    "        gradients = optimizer.compute_gradients(cost)\n",
    "        capped_gradients = [(tf.clip_by_value(grad, -5., 5.), var) for grad, var in gradients if grad is not None]\n",
    "        train_op = optimizer.apply_gradients(capped_gradients)\n",
    "print(\"Graph is built.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "iSkOPDO3kADU",
    "outputId": "2ea26a29-92e0-434a-bce7-18a8d053d896"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shortest text length: 4\n",
      "The longest text length: 1528\n"
     ]
    }
   ],
   "source": [
    "#start = 200000\n",
    "#end = start + 300000\n",
    "#sorted_summaries_short = sorted_summaries[start:end]\n",
    "#sorted_texts_short = sorted_texts[start:end]\n",
    "sorted_summaries_short = sorted_summaries\n",
    "sorted_texts_short = sorted_texts\n",
    "print(\"The shortest text length:\", len(sorted_texts_short[0]))\n",
    "print(\"The longest text length:\",len(sorted_texts_short[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_epoch = 6\n",
    "update_check = (len(sorted_texts_short)//batch_size//per_epoch)-1\n",
    "update_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss for this update: -29.325\n",
      "New Record!\n",
      "Average loss for this update: -9.229\n",
      "New Record!\n"
     ]
    }
   ],
   "source": [
    "# Train the Model\n",
    "learning_rate_decay = 0.95\n",
    "min_learning_rate = 0.0005\n",
    "display_step = 20 # Check training loss after every 20 batches\n",
    "stop_early = 0 \n",
    "stop = 3 # If the update loss does not decrease in 3 consecutive update checks, stop training\n",
    "per_epoch = 6 # Make 3 update checks per epoch\n",
    "update_check = (len(sorted_texts_short)//batch_size//per_epoch)-1\n",
    "\n",
    "update_loss = 0 \n",
    "batch_loss = 0\n",
    "summary_update_loss = [] # Record the update losses for saving improvements in the model\n",
    "\n",
    "checkpoint = \"./best_model.ckpt\" \n",
    "with tf.Session(graph=train_graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # If we want to continue training a previous session\n",
    "    #loader = tf.train.import_meta_graph(\"./\" + checkpoint + '.meta')\n",
    "    #loader.restore(sess, checkpoint)\n",
    "    \n",
    "    for epoch_i in range(1, epochs+1):\n",
    "        update_loss = 0\n",
    "        batch_loss = 0\n",
    "        for batch_i, (summaries_batch, texts_batch, summaries_lengths, texts_lengths) in enumerate(\n",
    "                get_batches(sorted_summaries_short, sorted_texts_short, batch_size)):\n",
    "            start_time = time.time()\n",
    "            _, loss = sess.run(\n",
    "                [train_op, cost],\n",
    "                {input_data: texts_batch,\n",
    "                 targets: summaries_batch,\n",
    "                 lr: learning_rate,\n",
    "                 summary_length: summaries_lengths,\n",
    "                 text_length: texts_lengths,\n",
    "                 keep_prob: keep_probability})\n",
    "\n",
    "            batch_loss += loss\n",
    "            update_loss += loss\n",
    "            end_time = time.time()\n",
    "            batch_time = end_time - start_time\n",
    "\n",
    "            if batch_i % display_step == 0 and batch_i > 0:\n",
    "                print('Epoch {:>3}/{} Batch {:>4}/{} - Loss: {:>6.3f}, Seconds: {:>4.2f}'\n",
    "                      .format(epoch_i,\n",
    "                              epochs, \n",
    "                              batch_i, \n",
    "                              len(sorted_texts_short) // batch_size, \n",
    "                              batch_loss / display_step, \n",
    "                              batch_time*display_step))\n",
    "                batch_loss = 0\n",
    "\n",
    "            if batch_i % update_check == 0 and batch_i > 0:\n",
    "                print(\"Average loss for this update:\", round(update_loss/update_check,3))\n",
    "                summary_update_loss.append(update_loss)\n",
    "                \n",
    "                # If the update loss is at a new minimum, save the model\n",
    "                if update_loss <= min(summary_update_loss):\n",
    "                    print('New Record!') \n",
    "                    stop_early = 0\n",
    "                    saver = tf.train.Saver() \n",
    "                    saver.save(sess, checkpoint)\n",
    "\n",
    "                else:\n",
    "                    print(\"No Improvement.\")\n",
    "                    stop_early += 1\n",
    "                    if stop_early == stop:\n",
    "                        break\n",
    "                update_loss = 0\n",
    "            \n",
    "                    \n",
    "        # Reduce learning rate, but not below its minimum value\n",
    "        learning_rate *= learning_rate_decay\n",
    "        if learning_rate < min_learning_rate:\n",
    "            learning_rate = min_learning_rate\n",
    "        \n",
    "        if stop_early == stop:\n",
    "            print(\"Stopping Training.\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KRpUma5TkEdI"
   },
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "integer division or modulo by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-7dc20ebf11e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     55\u001b[0m                 \u001b[0;31m#saver.save(sess, checkpoint)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_i\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mupdate_check\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbatch_i\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Average loss for this update:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupdate_loss\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mupdate_check\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                 \u001b[0msummary_update_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupdate_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: integer division or modulo by zero"
     ]
    }
   ],
   "source": [
    "learning_rate_decay = 0.95\n",
    "min_learning_rate = 0.0005\n",
    "display_step = 20 # Check training loss after every 20 batches\n",
    "stop_early = 0 \n",
    "stop = 6 #3 # If the update loss does not decrease in 3 consecutive update checks, stop training\n",
    "per_epoch = 3 # Make 3 update checks per epoch\n",
    "update_check = (len(sorted_texts_short)//batch_size//per_epoch)-1\n",
    "\n",
    "update_loss = 0 \n",
    "batch_loss = 0\n",
    "summary_update_loss = [] # Record the update losses for saving improvements in the model\n",
    "\n",
    "  \n",
    "tf.reset_default_graph()\n",
    "checkpoint = \"./best_model.ckpt\"\n",
    "with tf.Session(graph=train_graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # If we want to continue training a previous session\n",
    "    # loader = tf.train.import_meta_graph(checkpoint + '.meta')\n",
    "    # loader.restore(sess, checkpoint)\n",
    "    #sess.run(tf.local_variables_initializer())\n",
    "\n",
    "    for epoch_i in range(1, epochs+1):\n",
    "        update_loss = 0\n",
    "        batch_loss = 0\n",
    "        for batch_i, (summaries_batch, texts_batch, summaries_lengths, texts_lengths) in enumerate(\n",
    "                get_batches(sorted_summaries_short, sorted_texts_short, batch_size)):\n",
    "            start_time = time.time()\n",
    "            _, loss = sess.run(\n",
    "                [train_op, cost],\n",
    "                {input_data: texts_batch,\n",
    "                 targets: summaries_batch,\n",
    "                 lr: learning_rate,\n",
    "                 summary_length: summaries_lengths,\n",
    "                 text_length: texts_lengths,\n",
    "                 keep_prob: keep_probability})\n",
    "\n",
    "            batch_loss += loss\n",
    "            update_loss += loss\n",
    "            end_time = time.time()\n",
    "            batch_time = end_time - start_time\n",
    "\n",
    "            if batch_i % display_step == 0 and batch_i > 0:\n",
    "                print('Epoch {:>3}/{} Batch {:>4}/{} - Loss: {:>6.3f}, Seconds: {:>4.2f}'\n",
    "                      .format(epoch_i,\n",
    "                              epochs, \n",
    "                              batch_i, \n",
    "                              len(sorted_texts_short) // batch_size, \n",
    "                              batch_loss / display_step, \n",
    "                              batch_time*display_step))\n",
    "                batch_loss = 0\n",
    "                \n",
    "                #saver = tf.train.Saver() \n",
    "                #saver.save(sess, checkpoint)\n",
    "                \n",
    "            if batch_i % update_check == 0 and batch_i > 0:\n",
    "                print(\"Average loss for this update:\", round(update_loss/update_check,3))\n",
    "                summary_update_loss.append(update_loss)\n",
    "                \n",
    "              \n",
    "                  \n",
    "                # If the update loss is at a new minimum, save the model\n",
    "                if update_loss <= min(summary_update_loss):\n",
    "                    print('New Record!') \n",
    "                    stop_early = 0\n",
    "                    saver = tf.train.Saver() \n",
    "                    saver.save(sess, checkpoint)\n",
    "\n",
    "                else:\n",
    "                    print(\"No Improvement.\")\n",
    "                    stop_early += 1\n",
    "                    if stop_early == stop:\n",
    "                        break\n",
    "                update_loss = 0\n",
    "            \n",
    "                    \n",
    "        # Reduce learning rate, but not below its minimum value\n",
    "        learning_rate *= learning_rate_decay\n",
    "        if learning_rate < min_learning_rate:\n",
    "            learning_rate = min_learning_rate\n",
    "        \n",
    "        if stop_early == stop:\n",
    "            print(\"Stopping Training.\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6lwZqK_hkKss"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/vika/python-environments/env/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from best_model.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['input',\n",
       " 'targets',\n",
       " 'learning_rate',\n",
       " 'keep_prob',\n",
       " 'summary_length',\n",
       " 'Const',\n",
       " 'max_dec_len',\n",
       " 'text_length',\n",
       " 'ReverseV2/axis',\n",
       " 'ReverseV2',\n",
       " 'embedding_lookup/params_0',\n",
       " 'embedding_lookup/axis',\n",
       " 'embedding_lookup',\n",
       " 'embedding_lookup/Identity',\n",
       " 'encoder_0/DropoutWrapperInit/Const',\n",
       " 'encoder_0/DropoutWrapperInit/Const_1',\n",
       " 'encoder_0/DropoutWrapperInit_1/Const',\n",
       " 'encoder_0/DropoutWrapperInit_1/Const_1',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/Rank',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/range/start',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/range/delta',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/range',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/concat/values_0',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/concat/axis',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/concat',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/transpose',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/sequence_length',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/Shape',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/strided_slice/stack',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/strided_slice/stack_1',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/strided_slice/stack_2',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/strided_slice',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims/dim',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/Const',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/concat/axis',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/concat',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/zeros/Const',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/zeros',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims_1/dim',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims_1',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/Const_1',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims_2/dim',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims_2',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/Const_2',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/concat_1/axis',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/concat_1',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/zeros_1/Const',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/zeros_1',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims_3/dim',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims_3',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/Const_3',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/Shape_1',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/stack',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/Equal',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/Const',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/All',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/Assert/Const',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/Assert/Const_1',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/Assert/Assert/data_0',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/Assert/Assert/data_2',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/Assert/Assert',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/CheckSeqLen',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/Shape_2',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/strided_slice_1/stack',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/strided_slice_1/stack_1',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/strided_slice_1/stack_2',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/strided_slice_1',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/Shape_3',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/strided_slice_2/stack',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/strided_slice_2/stack_1',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/strided_slice_2/stack_2',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/strided_slice_2',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/ExpandDims/dim',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/ExpandDims',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/Const_1',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/concat_1/axis',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/concat_1',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/zeros/Const',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/zeros',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/Const_2',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/Min',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/Const_3',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/Max',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/time',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/TensorArray',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/TensorArray_1',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/TensorArrayUnstack/Shape',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/TensorArrayUnstack/strided_slice/stack',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/TensorArrayUnstack/strided_slice/stack_1',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/TensorArrayUnstack/strided_slice/stack_2',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/TensorArrayUnstack/strided_slice',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/TensorArrayUnstack/range/start',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/TensorArrayUnstack/range/delta',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/TensorArrayUnstack/range',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/Maximum/x',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/Maximum',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/Minimum',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/iteration_counter',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/Enter',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/Enter_1',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/Enter_2',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/Enter_3',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/Enter_4',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/Merge',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/Merge_1',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/Merge_2',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/Merge_3',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/Merge_4',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/Less/Enter',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/Less',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/Less_1/Enter',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/Less_1',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/LogicalAnd',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/LoopCond',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/Switch',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/Switch_1',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/Switch_2',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/Switch_3',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/Switch_4',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/Identity',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/Identity_1',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/Identity_2',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/Identity_3',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/Identity_4',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/add/y',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/add',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter_1',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/TensorArrayReadV3',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/GreaterEqual/Enter',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/GreaterEqual',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/sub/x',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/sub/Enter',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/sub',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/dropout/Shape',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/dropout/sub/x',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/dropout/sub',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/dropout/random_uniform/min',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/dropout/random_uniform/max',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/dropout/random_uniform/RandomUniform',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/dropout/random_uniform/sub',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/dropout/random_uniform/mul',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/dropout/random_uniform',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/dropout/add',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/dropout/Floor',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/dropout/truediv',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/dropout/mul',\n",
       " 'encoder_0/bidirectional_rnn/fw/lstm_cell/kernel/Initializer/random_uniform/shape',\n",
       " 'encoder_0/bidirectional_rnn/fw/lstm_cell/kernel/Initializer/random_uniform/min',\n",
       " 'encoder_0/bidirectional_rnn/fw/lstm_cell/kernel/Initializer/random_uniform/max',\n",
       " 'encoder_0/bidirectional_rnn/fw/lstm_cell/kernel/Initializer/random_uniform/RandomUniform',\n",
       " 'encoder_0/bidirectional_rnn/fw/lstm_cell/kernel/Initializer/random_uniform/sub',\n",
       " 'encoder_0/bidirectional_rnn/fw/lstm_cell/kernel/Initializer/random_uniform/mul',\n",
       " 'encoder_0/bidirectional_rnn/fw/lstm_cell/kernel/Initializer/random_uniform',\n",
       " 'encoder_0/bidirectional_rnn/fw/lstm_cell/kernel',\n",
       " 'encoder_0/bidirectional_rnn/fw/lstm_cell/kernel/IsInitialized/VarIsInitializedOp',\n",
       " 'encoder_0/bidirectional_rnn/fw/lstm_cell/kernel/Assign',\n",
       " 'encoder_0/bidirectional_rnn/fw/lstm_cell/kernel/Read/ReadVariableOp',\n",
       " 'encoder_0/bidirectional_rnn/fw/lstm_cell/kernel/Read/Identity',\n",
       " 'encoder_0/bidirectional_rnn/fw/lstm_cell/bias/Initializer/zeros/shape_as_tensor',\n",
       " 'encoder_0/bidirectional_rnn/fw/lstm_cell/bias/Initializer/zeros/Const',\n",
       " 'encoder_0/bidirectional_rnn/fw/lstm_cell/bias/Initializer/zeros',\n",
       " 'encoder_0/bidirectional_rnn/fw/lstm_cell/bias',\n",
       " 'encoder_0/bidirectional_rnn/fw/lstm_cell/bias/IsInitialized/VarIsInitializedOp',\n",
       " 'encoder_0/bidirectional_rnn/fw/lstm_cell/bias/Assign',\n",
       " 'encoder_0/bidirectional_rnn/fw/lstm_cell/bias/Read/ReadVariableOp',\n",
       " 'encoder_0/bidirectional_rnn/fw/lstm_cell/bias/Read/Identity',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/lstm_cell/concat/axis',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/lstm_cell/concat',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/lstm_cell/MatMul/Enter',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/lstm_cell/MatMul',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/lstm_cell/BiasAdd/Enter',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/lstm_cell/BiasAdd',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/lstm_cell/Const',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/lstm_cell/split/split_dim',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/lstm_cell/split',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/lstm_cell/add/y',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/lstm_cell/add',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/lstm_cell/Sigmoid',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/lstm_cell/mul',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/lstm_cell/Sigmoid_1',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/lstm_cell/Tanh',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/lstm_cell/mul_1',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/lstm_cell/add_1',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/lstm_cell/Sigmoid_2',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/lstm_cell/Tanh_1',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/lstm_cell/mul_2',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/Select/Enter',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/Select',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/Select_1',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/Select_2',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3/Enter',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/add_1/y',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/add_1',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/NextIteration',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/NextIteration_1',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/NextIteration_2',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/NextIteration_3',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/NextIteration_4',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/Exit',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/Exit_1',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/Exit_2',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/Exit_3',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/while/Exit_4',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/TensorArrayStack/TensorArraySizeV3',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/TensorArrayStack/range/start',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/TensorArrayStack/range/delta',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/TensorArrayStack/range',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/TensorArrayStack/TensorArrayGatherV3',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/Const_4',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/Rank_1',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/range_1/start',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/range_1/delta',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/range_1',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/concat_2/values_0',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/concat_2/axis',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/concat_2',\n",
       " 'encoder_0/bidirectional_rnn/fw/fw/transpose_1',\n",
       " 'encoder_0/bidirectional_rnn/bw/ReverseSequence',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/Rank',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/range/start',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/range/delta',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/range',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/concat/values_0',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/concat/axis',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/concat',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/transpose',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/sequence_length',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/Shape',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/strided_slice/stack',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/strided_slice/stack_1',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/strided_slice/stack_2',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/strided_slice',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims/dim',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/Const',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/concat/axis',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/concat',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/zeros/Const',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/zeros',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims_1/dim',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims_1',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/Const_1',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims_2/dim',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims_2',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/Const_2',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/concat_1/axis',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/concat_1',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/zeros_1/Const',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/zeros_1',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims_3/dim',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims_3',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/Const_3',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/Shape_1',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/stack',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/Equal',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/Const',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/All',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/Assert/Const',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/Assert/Const_1',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/Assert/Assert/data_0',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/Assert/Assert/data_2',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/Assert/Assert',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/CheckSeqLen',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/Shape_2',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/strided_slice_1/stack',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/strided_slice_1/stack_1',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/strided_slice_1/stack_2',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/strided_slice_1',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/Shape_3',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/strided_slice_2/stack',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/strided_slice_2/stack_1',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/strided_slice_2/stack_2',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/strided_slice_2',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/ExpandDims/dim',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/ExpandDims',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/Const_1',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/concat_1/axis',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/concat_1',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/zeros/Const',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/zeros',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/Const_2',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/Min',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/Const_3',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/Max',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/time',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/TensorArray',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/TensorArray_1',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/TensorArrayUnstack/Shape',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/TensorArrayUnstack/strided_slice/stack',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/TensorArrayUnstack/strided_slice/stack_1',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/TensorArrayUnstack/strided_slice/stack_2',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/TensorArrayUnstack/strided_slice',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/TensorArrayUnstack/range/start',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/TensorArrayUnstack/range/delta',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/TensorArrayUnstack/range',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/Maximum/x',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/Maximum',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/Minimum',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/iteration_counter',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/Enter',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/Enter_1',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/Enter_2',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/Enter_3',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/Enter_4',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/Merge',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/Merge_1',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/Merge_2',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/Merge_3',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/Merge_4',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/Less/Enter',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/Less',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/Less_1/Enter',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/Less_1',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/LogicalAnd',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/LoopCond',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/Switch',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/Switch_1',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/Switch_2',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/Switch_3',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/Switch_4',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/Identity',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/Identity_1',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/Identity_2',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/Identity_3',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/Identity_4',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/add/y',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/add',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter_1',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/TensorArrayReadV3',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/GreaterEqual/Enter',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/GreaterEqual',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/sub/x',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/sub/Enter',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/sub',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/dropout/Shape',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/dropout/sub/x',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/dropout/sub',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/dropout/random_uniform/min',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/dropout/random_uniform/max',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/dropout/random_uniform/RandomUniform',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/dropout/random_uniform/sub',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/dropout/random_uniform/mul',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/dropout/random_uniform',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/dropout/add',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/dropout/Floor',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/dropout/truediv',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/dropout/mul',\n",
       " 'encoder_0/bidirectional_rnn/bw/lstm_cell/kernel/Initializer/random_uniform/shape',\n",
       " 'encoder_0/bidirectional_rnn/bw/lstm_cell/kernel/Initializer/random_uniform/min',\n",
       " 'encoder_0/bidirectional_rnn/bw/lstm_cell/kernel/Initializer/random_uniform/max',\n",
       " 'encoder_0/bidirectional_rnn/bw/lstm_cell/kernel/Initializer/random_uniform/RandomUniform',\n",
       " 'encoder_0/bidirectional_rnn/bw/lstm_cell/kernel/Initializer/random_uniform/sub',\n",
       " 'encoder_0/bidirectional_rnn/bw/lstm_cell/kernel/Initializer/random_uniform/mul',\n",
       " 'encoder_0/bidirectional_rnn/bw/lstm_cell/kernel/Initializer/random_uniform',\n",
       " 'encoder_0/bidirectional_rnn/bw/lstm_cell/kernel',\n",
       " 'encoder_0/bidirectional_rnn/bw/lstm_cell/kernel/IsInitialized/VarIsInitializedOp',\n",
       " 'encoder_0/bidirectional_rnn/bw/lstm_cell/kernel/Assign',\n",
       " 'encoder_0/bidirectional_rnn/bw/lstm_cell/kernel/Read/ReadVariableOp',\n",
       " 'encoder_0/bidirectional_rnn/bw/lstm_cell/kernel/Read/Identity',\n",
       " 'encoder_0/bidirectional_rnn/bw/lstm_cell/bias/Initializer/zeros/shape_as_tensor',\n",
       " 'encoder_0/bidirectional_rnn/bw/lstm_cell/bias/Initializer/zeros/Const',\n",
       " 'encoder_0/bidirectional_rnn/bw/lstm_cell/bias/Initializer/zeros',\n",
       " 'encoder_0/bidirectional_rnn/bw/lstm_cell/bias',\n",
       " 'encoder_0/bidirectional_rnn/bw/lstm_cell/bias/IsInitialized/VarIsInitializedOp',\n",
       " 'encoder_0/bidirectional_rnn/bw/lstm_cell/bias/Assign',\n",
       " 'encoder_0/bidirectional_rnn/bw/lstm_cell/bias/Read/ReadVariableOp',\n",
       " 'encoder_0/bidirectional_rnn/bw/lstm_cell/bias/Read/Identity',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/lstm_cell/concat/axis',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/lstm_cell/concat',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/lstm_cell/MatMul/Enter',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/lstm_cell/MatMul',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/lstm_cell/BiasAdd/Enter',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/lstm_cell/BiasAdd',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/lstm_cell/Const',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/lstm_cell/split/split_dim',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/lstm_cell/split',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/lstm_cell/add/y',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/lstm_cell/add',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/lstm_cell/Sigmoid',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/lstm_cell/mul',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/lstm_cell/Sigmoid_1',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/lstm_cell/Tanh',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/lstm_cell/mul_1',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/lstm_cell/add_1',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/lstm_cell/Sigmoid_2',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/lstm_cell/Tanh_1',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/lstm_cell/mul_2',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/Select/Enter',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/Select',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/Select_1',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/Select_2',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3/Enter',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/add_1/y',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/add_1',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/NextIteration',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/NextIteration_1',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/NextIteration_2',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/NextIteration_3',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/NextIteration_4',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/Exit',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/Exit_1',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/Exit_2',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/Exit_3',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/while/Exit_4',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/TensorArrayStack/TensorArraySizeV3',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/TensorArrayStack/range/start',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/TensorArrayStack/range/delta',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/TensorArrayStack/range',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/TensorArrayStack/TensorArrayGatherV3',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/Const_4',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/Rank_1',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/range_1/start',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/range_1/delta',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/range_1',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/concat_2/values_0',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/concat_2/axis',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/concat_2',\n",
       " 'encoder_0/bidirectional_rnn/bw/bw/transpose_1',\n",
       " 'encoder_0/ReverseSequence',\n",
       " 'encoder_1/DropoutWrapperInit/Const',\n",
       " 'encoder_1/DropoutWrapperInit/Const_1',\n",
       " 'encoder_1/DropoutWrapperInit_1/Const',\n",
       " 'encoder_1/DropoutWrapperInit_1/Const_1',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/Rank',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/range/start',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/range/delta',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/range',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/concat/values_0',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/concat/axis',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/concat',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/transpose',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/sequence_length',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/Shape',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/strided_slice/stack',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/strided_slice/stack_1',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/strided_slice/stack_2',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/strided_slice',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims/dim',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/Const',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/concat/axis',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/concat',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/zeros/Const',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/zeros',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims_1/dim',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims_1',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/Const_1',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims_2/dim',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims_2',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/Const_2',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/concat_1/axis',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/concat_1',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/zeros_1/Const',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/zeros_1',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims_3/dim',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims_3',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/DropoutWrapperZeroState/LSTMCellZeroState/Const_3',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/Shape_1',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/stack',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/Equal',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/Const',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/All',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/Assert/Const',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/Assert/Const_1',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/Assert/Assert/data_0',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/Assert/Assert/data_2',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/Assert/Assert',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/CheckSeqLen',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/Shape_2',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/strided_slice_1/stack',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/strided_slice_1/stack_1',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/strided_slice_1/stack_2',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/strided_slice_1',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/Shape_3',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/strided_slice_2/stack',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/strided_slice_2/stack_1',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/strided_slice_2/stack_2',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/strided_slice_2',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/ExpandDims/dim',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/ExpandDims',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/Const_1',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/concat_1/axis',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/concat_1',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/zeros/Const',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/zeros',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/Const_2',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/Min',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/Const_3',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/Max',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/time',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/TensorArray',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/TensorArray_1',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/TensorArrayUnstack/Shape',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/TensorArrayUnstack/strided_slice/stack',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/TensorArrayUnstack/strided_slice/stack_1',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/TensorArrayUnstack/strided_slice/stack_2',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/TensorArrayUnstack/strided_slice',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/TensorArrayUnstack/range/start',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/TensorArrayUnstack/range/delta',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/TensorArrayUnstack/range',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/Maximum/x',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/Maximum',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/Minimum',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/iteration_counter',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/Enter',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/Enter_1',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/Enter_2',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/Enter_3',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/Enter_4',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/Merge',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/Merge_1',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/Merge_2',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/Merge_3',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/Merge_4',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/Less/Enter',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/Less',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/Less_1/Enter',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/Less_1',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/LogicalAnd',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/LoopCond',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/Switch',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/Switch_1',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/Switch_2',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/Switch_3',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/Switch_4',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/Identity',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/Identity_1',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/Identity_2',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/Identity_3',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/Identity_4',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/add/y',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/add',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter_1',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/TensorArrayReadV3',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/GreaterEqual/Enter',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/GreaterEqual',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/sub/x',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/sub/Enter',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/sub',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/dropout/Shape',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/dropout/sub/x',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/dropout/sub',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/dropout/random_uniform/min',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/dropout/random_uniform/max',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/dropout/random_uniform/RandomUniform',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/dropout/random_uniform/sub',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/dropout/random_uniform/mul',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/dropout/random_uniform',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/dropout/add',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/dropout/Floor',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/dropout/truediv',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/dropout/mul',\n",
       " 'encoder_1/bidirectional_rnn/fw/lstm_cell/kernel/Initializer/random_uniform/shape',\n",
       " 'encoder_1/bidirectional_rnn/fw/lstm_cell/kernel/Initializer/random_uniform/min',\n",
       " 'encoder_1/bidirectional_rnn/fw/lstm_cell/kernel/Initializer/random_uniform/max',\n",
       " 'encoder_1/bidirectional_rnn/fw/lstm_cell/kernel/Initializer/random_uniform/RandomUniform',\n",
       " 'encoder_1/bidirectional_rnn/fw/lstm_cell/kernel/Initializer/random_uniform/sub',\n",
       " 'encoder_1/bidirectional_rnn/fw/lstm_cell/kernel/Initializer/random_uniform/mul',\n",
       " 'encoder_1/bidirectional_rnn/fw/lstm_cell/kernel/Initializer/random_uniform',\n",
       " 'encoder_1/bidirectional_rnn/fw/lstm_cell/kernel',\n",
       " 'encoder_1/bidirectional_rnn/fw/lstm_cell/kernel/IsInitialized/VarIsInitializedOp',\n",
       " 'encoder_1/bidirectional_rnn/fw/lstm_cell/kernel/Assign',\n",
       " 'encoder_1/bidirectional_rnn/fw/lstm_cell/kernel/Read/ReadVariableOp',\n",
       " 'encoder_1/bidirectional_rnn/fw/lstm_cell/kernel/Read/Identity',\n",
       " 'encoder_1/bidirectional_rnn/fw/lstm_cell/bias/Initializer/zeros/shape_as_tensor',\n",
       " 'encoder_1/bidirectional_rnn/fw/lstm_cell/bias/Initializer/zeros/Const',\n",
       " 'encoder_1/bidirectional_rnn/fw/lstm_cell/bias/Initializer/zeros',\n",
       " 'encoder_1/bidirectional_rnn/fw/lstm_cell/bias',\n",
       " 'encoder_1/bidirectional_rnn/fw/lstm_cell/bias/IsInitialized/VarIsInitializedOp',\n",
       " 'encoder_1/bidirectional_rnn/fw/lstm_cell/bias/Assign',\n",
       " 'encoder_1/bidirectional_rnn/fw/lstm_cell/bias/Read/ReadVariableOp',\n",
       " 'encoder_1/bidirectional_rnn/fw/lstm_cell/bias/Read/Identity',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/lstm_cell/concat/axis',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/lstm_cell/concat',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/lstm_cell/MatMul/Enter',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/lstm_cell/MatMul',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/lstm_cell/BiasAdd/Enter',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/lstm_cell/BiasAdd',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/lstm_cell/Const',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/lstm_cell/split/split_dim',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/lstm_cell/split',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/lstm_cell/add/y',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/lstm_cell/add',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/lstm_cell/Sigmoid',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/lstm_cell/mul',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/lstm_cell/Sigmoid_1',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/lstm_cell/Tanh',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/lstm_cell/mul_1',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/lstm_cell/add_1',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/lstm_cell/Sigmoid_2',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/lstm_cell/Tanh_1',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/lstm_cell/mul_2',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/Select/Enter',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/Select',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/Select_1',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/Select_2',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3/Enter',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/add_1/y',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/add_1',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/NextIteration',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/NextIteration_1',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/NextIteration_2',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/NextIteration_3',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/NextIteration_4',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/Exit',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/Exit_1',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/Exit_2',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/Exit_3',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/while/Exit_4',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/TensorArrayStack/TensorArraySizeV3',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/TensorArrayStack/range/start',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/TensorArrayStack/range/delta',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/TensorArrayStack/range',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/TensorArrayStack/TensorArrayGatherV3',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/Const_4',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/Rank_1',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/range_1/start',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/range_1/delta',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/range_1',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/concat_2/values_0',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/concat_2/axis',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/concat_2',\n",
       " 'encoder_1/bidirectional_rnn/fw/fw/transpose_1',\n",
       " 'encoder_1/bidirectional_rnn/bw/ReverseSequence',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/Rank',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/range/start',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/range/delta',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/range',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/concat/values_0',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/concat/axis',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/concat',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/transpose',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/sequence_length',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/Shape',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/strided_slice/stack',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/strided_slice/stack_1',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/strided_slice/stack_2',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/strided_slice',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims/dim',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/Const',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/concat/axis',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/concat',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/zeros/Const',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/zeros',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims_1/dim',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims_1',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/Const_1',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims_2/dim',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims_2',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/Const_2',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/concat_1/axis',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/concat_1',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/zeros_1/Const',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/zeros_1',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims_3/dim',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/ExpandDims_3',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/DropoutWrapperZeroState/LSTMCellZeroState/Const_3',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/Shape_1',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/stack',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/Equal',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/Const',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/All',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/Assert/Const',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/Assert/Const_1',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/Assert/Assert/data_0',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/Assert/Assert/data_2',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/Assert/Assert',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/CheckSeqLen',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/Shape_2',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/strided_slice_1/stack',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/strided_slice_1/stack_1',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/strided_slice_1/stack_2',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/strided_slice_1',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/Shape_3',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/strided_slice_2/stack',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/strided_slice_2/stack_1',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/strided_slice_2/stack_2',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/strided_slice_2',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/ExpandDims/dim',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/ExpandDims',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/Const_1',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/concat_1/axis',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/concat_1',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/zeros/Const',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/zeros',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/Const_2',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/Min',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/Const_3',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/Max',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/time',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/TensorArray',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/TensorArray_1',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/TensorArrayUnstack/Shape',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/TensorArrayUnstack/strided_slice/stack',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/TensorArrayUnstack/strided_slice/stack_1',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/TensorArrayUnstack/strided_slice/stack_2',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/TensorArrayUnstack/strided_slice',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/TensorArrayUnstack/range/start',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/TensorArrayUnstack/range/delta',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/TensorArrayUnstack/range',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/Maximum/x',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/Maximum',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/Minimum',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/iteration_counter',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/Enter',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/Enter_1',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/Enter_2',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/Enter_3',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/Enter_4',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/Merge',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/Merge_1',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/Merge_2',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/Merge_3',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/Merge_4',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/Less/Enter',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/Less',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/Less_1/Enter',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/Less_1',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/LogicalAnd',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/LoopCond',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/Switch',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/Switch_1',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/Switch_2',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/Switch_3',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/Switch_4',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/Identity',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/Identity_1',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/Identity_2',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/Identity_3',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/Identity_4',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/add/y',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/add',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/TensorArrayReadV3/Enter_1',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/TensorArrayReadV3',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/GreaterEqual/Enter',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/GreaterEqual',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/sub/x',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/sub/Enter',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/sub',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/dropout/Shape',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/dropout/sub/x',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/dropout/sub',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/dropout/random_uniform/min',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/dropout/random_uniform/max',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/dropout/random_uniform/RandomUniform',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/dropout/random_uniform/sub',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/dropout/random_uniform/mul',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/dropout/random_uniform',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/dropout/add',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/dropout/Floor',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/dropout/truediv',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/dropout/mul',\n",
       " 'encoder_1/bidirectional_rnn/bw/lstm_cell/kernel/Initializer/random_uniform/shape',\n",
       " 'encoder_1/bidirectional_rnn/bw/lstm_cell/kernel/Initializer/random_uniform/min',\n",
       " 'encoder_1/bidirectional_rnn/bw/lstm_cell/kernel/Initializer/random_uniform/max',\n",
       " 'encoder_1/bidirectional_rnn/bw/lstm_cell/kernel/Initializer/random_uniform/RandomUniform',\n",
       " 'encoder_1/bidirectional_rnn/bw/lstm_cell/kernel/Initializer/random_uniform/sub',\n",
       " 'encoder_1/bidirectional_rnn/bw/lstm_cell/kernel/Initializer/random_uniform/mul',\n",
       " 'encoder_1/bidirectional_rnn/bw/lstm_cell/kernel/Initializer/random_uniform',\n",
       " 'encoder_1/bidirectional_rnn/bw/lstm_cell/kernel',\n",
       " 'encoder_1/bidirectional_rnn/bw/lstm_cell/kernel/IsInitialized/VarIsInitializedOp',\n",
       " 'encoder_1/bidirectional_rnn/bw/lstm_cell/kernel/Assign',\n",
       " 'encoder_1/bidirectional_rnn/bw/lstm_cell/kernel/Read/ReadVariableOp',\n",
       " 'encoder_1/bidirectional_rnn/bw/lstm_cell/kernel/Read/Identity',\n",
       " 'encoder_1/bidirectional_rnn/bw/lstm_cell/bias/Initializer/zeros/shape_as_tensor',\n",
       " 'encoder_1/bidirectional_rnn/bw/lstm_cell/bias/Initializer/zeros/Const',\n",
       " 'encoder_1/bidirectional_rnn/bw/lstm_cell/bias/Initializer/zeros',\n",
       " 'encoder_1/bidirectional_rnn/bw/lstm_cell/bias',\n",
       " 'encoder_1/bidirectional_rnn/bw/lstm_cell/bias/IsInitialized/VarIsInitializedOp',\n",
       " 'encoder_1/bidirectional_rnn/bw/lstm_cell/bias/Assign',\n",
       " 'encoder_1/bidirectional_rnn/bw/lstm_cell/bias/Read/ReadVariableOp',\n",
       " 'encoder_1/bidirectional_rnn/bw/lstm_cell/bias/Read/Identity',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/lstm_cell/concat/axis',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/lstm_cell/concat',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/lstm_cell/MatMul/Enter',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/lstm_cell/MatMul',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/lstm_cell/BiasAdd/Enter',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/lstm_cell/BiasAdd',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/lstm_cell/Const',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/lstm_cell/split/split_dim',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/lstm_cell/split',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/lstm_cell/add/y',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/lstm_cell/add',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/lstm_cell/Sigmoid',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/lstm_cell/mul',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/lstm_cell/Sigmoid_1',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/lstm_cell/Tanh',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/lstm_cell/mul_1',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/lstm_cell/add_1',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/lstm_cell/Sigmoid_2',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/lstm_cell/Tanh_1',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/lstm_cell/mul_2',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/Select/Enter',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/Select',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/Select_1',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/Select_2',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3/Enter',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/TensorArrayWrite/TensorArrayWriteV3',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/add_1/y',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/add_1',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/NextIteration',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/NextIteration_1',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/NextIteration_2',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/NextIteration_3',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/NextIteration_4',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/Exit',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/Exit_1',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/Exit_2',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/Exit_3',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/while/Exit_4',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/TensorArrayStack/TensorArraySizeV3',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/TensorArrayStack/range/start',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/TensorArrayStack/range/delta',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/TensorArrayStack/range',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/TensorArrayStack/TensorArrayGatherV3',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/Const_4',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/Rank_1',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/range_1/start',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/range_1/delta',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/range_1',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/concat_2/values_0',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/concat_2/axis',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/concat_2',\n",
       " 'encoder_1/bidirectional_rnn/bw/bw/transpose_1',\n",
       " 'encoder_1/ReverseSequence',\n",
       " 'concat/axis',\n",
       " 'concat',\n",
       " 'StridedSlice/begin',\n",
       " 'StridedSlice/end',\n",
       " 'StridedSlice/strides',\n",
       " 'StridedSlice',\n",
       " 'Fill/dims',\n",
       " 'Fill/value',\n",
       " 'Fill',\n",
       " 'concat_1/axis',\n",
       " 'concat_1',\n",
       " 'embedding_lookup_1/params_0',\n",
       " 'embedding_lookup_1/axis',\n",
       " 'embedding_lookup_1',\n",
       " 'embedding_lookup_1/Identity',\n",
       " 'decoder_0/DropoutWrapperInit/Const',\n",
       " 'decoder_0/DropoutWrapperInit/Const_1',\n",
       " 'decoder_1/DropoutWrapperInit/Const',\n",
       " 'decoder_1/DropoutWrapperInit/Const_1',\n",
       " 'BahdanauAttention/Shape',\n",
       " 'BahdanauAttention/strided_slice/stack',\n",
       " 'BahdanauAttention/strided_slice/stack_1',\n",
       " 'BahdanauAttention/strided_slice/stack_2',\n",
       " 'BahdanauAttention/strided_slice',\n",
       " 'BahdanauAttention/SequenceMask/Const',\n",
       " 'BahdanauAttention/SequenceMask/Const_1',\n",
       " 'BahdanauAttention/SequenceMask/Range',\n",
       " 'BahdanauAttention/SequenceMask/ExpandDims/dim',\n",
       " 'BahdanauAttention/SequenceMask/ExpandDims',\n",
       " 'BahdanauAttention/SequenceMask/Cast',\n",
       " 'BahdanauAttention/SequenceMask/Less',\n",
       " 'BahdanauAttention/SequenceMask/Cast_1',\n",
       " 'BahdanauAttention/Shape_1',\n",
       " 'BahdanauAttention/strided_slice_1/stack',\n",
       " 'BahdanauAttention/strided_slice_1/stack_1',\n",
       " 'BahdanauAttention/strided_slice_1/stack_2',\n",
       " 'BahdanauAttention/strided_slice_1',\n",
       " 'BahdanauAttention/ones/shape_as_tensor',\n",
       " 'BahdanauAttention/ones/Const',\n",
       " 'BahdanauAttention/ones',\n",
       " 'BahdanauAttention/Shape_2',\n",
       " 'BahdanauAttention/strided_slice_2/stack',\n",
       " 'BahdanauAttention/strided_slice_2/stack_1',\n",
       " 'BahdanauAttention/strided_slice_2/stack_2',\n",
       " 'BahdanauAttention/strided_slice_2',\n",
       " 'BahdanauAttention/assert_equal/Equal',\n",
       " 'BahdanauAttention/assert_equal/Const',\n",
       " 'BahdanauAttention/assert_equal/All',\n",
       " 'BahdanauAttention/assert_equal/Assert/Const',\n",
       " 'BahdanauAttention/assert_equal/Assert/Const_1',\n",
       " 'BahdanauAttention/assert_equal/Assert/Const_2',\n",
       " 'BahdanauAttention/assert_equal/Assert/Const_3',\n",
       " 'BahdanauAttention/assert_equal/Assert/Assert/data_0',\n",
       " 'BahdanauAttention/assert_equal/Assert/Assert/data_1',\n",
       " 'BahdanauAttention/assert_equal/Assert/Assert/data_2',\n",
       " 'BahdanauAttention/assert_equal/Assert/Assert/data_4',\n",
       " 'BahdanauAttention/assert_equal/Assert/Assert',\n",
       " 'BahdanauAttention/Shape_3',\n",
       " 'BahdanauAttention/concat/axis',\n",
       " 'BahdanauAttention/concat',\n",
       " 'BahdanauAttention/Reshape',\n",
       " 'BahdanauAttention/mul',\n",
       " 'memory_layer/kernel/Initializer/random_uniform/shape',\n",
       " 'memory_layer/kernel/Initializer/random_uniform/min',\n",
       " 'memory_layer/kernel/Initializer/random_uniform/max',\n",
       " 'memory_layer/kernel/Initializer/random_uniform/RandomUniform',\n",
       " 'memory_layer/kernel/Initializer/random_uniform/sub',\n",
       " 'memory_layer/kernel/Initializer/random_uniform/mul',\n",
       " 'memory_layer/kernel/Initializer/random_uniform',\n",
       " 'memory_layer/kernel',\n",
       " 'memory_layer/kernel/Assign',\n",
       " 'memory_layer/kernel/read',\n",
       " 'BahdanauAttention/memory_layer/Tensordot/axes',\n",
       " 'BahdanauAttention/memory_layer/Tensordot/free',\n",
       " 'BahdanauAttention/memory_layer/Tensordot/Shape',\n",
       " 'BahdanauAttention/memory_layer/Tensordot/GatherV2/axis',\n",
       " 'BahdanauAttention/memory_layer/Tensordot/GatherV2',\n",
       " 'BahdanauAttention/memory_layer/Tensordot/GatherV2_1/axis',\n",
       " 'BahdanauAttention/memory_layer/Tensordot/GatherV2_1',\n",
       " 'BahdanauAttention/memory_layer/Tensordot/Const',\n",
       " 'BahdanauAttention/memory_layer/Tensordot/Prod',\n",
       " 'BahdanauAttention/memory_layer/Tensordot/Const_1',\n",
       " 'BahdanauAttention/memory_layer/Tensordot/Prod_1',\n",
       " 'BahdanauAttention/memory_layer/Tensordot/concat/axis',\n",
       " 'BahdanauAttention/memory_layer/Tensordot/concat',\n",
       " 'BahdanauAttention/memory_layer/Tensordot/stack',\n",
       " 'BahdanauAttention/memory_layer/Tensordot/transpose',\n",
       " 'BahdanauAttention/memory_layer/Tensordot/Reshape',\n",
       " 'BahdanauAttention/memory_layer/Tensordot/transpose_1/perm',\n",
       " 'BahdanauAttention/memory_layer/Tensordot/transpose_1',\n",
       " 'BahdanauAttention/memory_layer/Tensordot/Reshape_1/shape',\n",
       " 'BahdanauAttention/memory_layer/Tensordot/Reshape_1',\n",
       " 'BahdanauAttention/memory_layer/Tensordot/MatMul',\n",
       " 'BahdanauAttention/memory_layer/Tensordot/Const_2',\n",
       " 'BahdanauAttention/memory_layer/Tensordot/concat_1/axis',\n",
       " 'BahdanauAttention/memory_layer/Tensordot/concat_1',\n",
       " 'BahdanauAttention/memory_layer/Tensordot',\n",
       " 'BahdanauAttention/Shape_4',\n",
       " 'BahdanauAttention/strided_slice_3/stack',\n",
       " 'BahdanauAttention/strided_slice_3/stack_1',\n",
       " 'BahdanauAttention/strided_slice_3/stack_2',\n",
       " 'BahdanauAttention/strided_slice_3',\n",
       " 'BahdanauAttention/Shape_5',\n",
       " 'BahdanauAttention/strided_slice_4/stack',\n",
       " 'BahdanauAttention/strided_slice_4/stack_1',\n",
       " 'BahdanauAttention/strided_slice_4/stack_2',\n",
       " 'BahdanauAttention/strided_slice_4',\n",
       " 'AttentionWrapperZeroState/DropoutWrapperZeroState/LSTMCellZeroState/Const',\n",
       " 'AttentionWrapperZeroState/DropoutWrapperZeroState/LSTMCellZeroState/Const_1',\n",
       " 'AttentionWrapperZeroState/DropoutWrapperZeroState/LSTMCellZeroState/concat/axis',\n",
       " 'AttentionWrapperZeroState/DropoutWrapperZeroState/LSTMCellZeroState/concat',\n",
       " 'AttentionWrapperZeroState/DropoutWrapperZeroState/LSTMCellZeroState/zeros/Const',\n",
       " 'AttentionWrapperZeroState/DropoutWrapperZeroState/LSTMCellZeroState/zeros',\n",
       " 'AttentionWrapperZeroState/DropoutWrapperZeroState/LSTMCellZeroState/Const_2',\n",
       " 'AttentionWrapperZeroState/DropoutWrapperZeroState/LSTMCellZeroState/Const_3',\n",
       " 'AttentionWrapperZeroState/DropoutWrapperZeroState/LSTMCellZeroState/Const_4',\n",
       " 'AttentionWrapperZeroState/DropoutWrapperZeroState/LSTMCellZeroState/Const_5',\n",
       " 'AttentionWrapperZeroState/DropoutWrapperZeroState/LSTMCellZeroState/concat_1/axis',\n",
       " 'AttentionWrapperZeroState/DropoutWrapperZeroState/LSTMCellZeroState/concat_1',\n",
       " 'AttentionWrapperZeroState/DropoutWrapperZeroState/LSTMCellZeroState/zeros_1/Const',\n",
       " 'AttentionWrapperZeroState/DropoutWrapperZeroState/LSTMCellZeroState/zeros_1',\n",
       " 'AttentionWrapperZeroState/DropoutWrapperZeroState/LSTMCellZeroState/Const_6',\n",
       " 'AttentionWrapperZeroState/DropoutWrapperZeroState/LSTMCellZeroState/Const_7',\n",
       " 'AttentionWrapperZeroState/assert_equal/x',\n",
       " 'AttentionWrapperZeroState/assert_equal/Equal',\n",
       " 'AttentionWrapperZeroState/assert_equal/Const',\n",
       " 'AttentionWrapperZeroState/assert_equal/All',\n",
       " 'AttentionWrapperZeroState/assert_equal/Assert/Const',\n",
       " 'AttentionWrapperZeroState/assert_equal/Assert/Const_1',\n",
       " 'AttentionWrapperZeroState/assert_equal/Assert/Const_2',\n",
       " 'AttentionWrapperZeroState/assert_equal/Assert/Const_3',\n",
       " 'AttentionWrapperZeroState/assert_equal/Assert/Assert/data_0',\n",
       " 'AttentionWrapperZeroState/assert_equal/Assert/Assert/data_1',\n",
       " 'AttentionWrapperZeroState/assert_equal/Assert/Assert/data_2',\n",
       " 'AttentionWrapperZeroState/assert_equal/Assert/Assert/data_4',\n",
       " 'AttentionWrapperZeroState/assert_equal/Assert/Assert',\n",
       " 'AttentionWrapperZeroState/checked_cell_state',\n",
       " 'AttentionWrapperZeroState/checked_cell_state_1',\n",
       " 'AttentionWrapperZeroState/Const',\n",
       " 'AttentionWrapperZeroState/ExpandDims/dim',\n",
       " 'AttentionWrapperZeroState/ExpandDims',\n",
       " 'AttentionWrapperZeroState/concat/axis',\n",
       " 'AttentionWrapperZeroState/concat',\n",
       " 'AttentionWrapperZeroState/zeros/Const',\n",
       " 'AttentionWrapperZeroState/zeros',\n",
       " 'AttentionWrapperZeroState/Const_1',\n",
       " 'AttentionWrapperZeroState/ExpandDims_1/dim',\n",
       " 'AttentionWrapperZeroState/ExpandDims_1',\n",
       " 'AttentionWrapperZeroState/zeros_1',\n",
       " 'AttentionWrapperZeroState/Const_2',\n",
       " 'AttentionWrapperZeroState/Const_3',\n",
       " 'AttentionWrapperZeroState/concat_1/axis',\n",
       " 'AttentionWrapperZeroState/concat_1',\n",
       " 'AttentionWrapperZeroState/zeros_2/Const',\n",
       " 'AttentionWrapperZeroState/zeros_2',\n",
       " 'AttentionWrapperZeroState/Const_4',\n",
       " 'AttentionWrapperZeroState/Const_5',\n",
       " 'AttentionWrapperZeroState/Const_6',\n",
       " 'AttentionWrapperZeroState/ExpandDims_2/dim',\n",
       " 'AttentionWrapperZeroState/ExpandDims_2',\n",
       " 'AttentionWrapperZeroState/concat_2/axis',\n",
       " 'AttentionWrapperZeroState/concat_2',\n",
       " ...]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = \"best_model.ckpt\" \n",
    "\n",
    "loaded_graph = tf.Graph()\n",
    "with tf.Session(graph=loaded_graph) as sess:\n",
    "    # Load saved model\n",
    "    loader = tf.train.import_meta_graph(checkpoint + '.meta')\n",
    "    loader.restore(sess, checkpoint)\n",
    "    names = []\n",
    "    [names.append(n.name) for n in loaded_graph.as_graph_def().node]\n",
    "names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d6abG-TxkW78"
   },
   "outputs": [],
   "source": [
    "def text_to_seq(text):\n",
    "    '''Prepare the text for the model'''\n",
    "    \n",
    "    text = clean_text(text)\n",
    "    return [vocab_to_int.get(word, vocab_to_int['<UNK>']) for word in text.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yUEenOMrlLT2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from best_model.ckpt\n",
      "Original Text: Побиті дороги – це перше, що розповість про те, що Лазурному ще є куди рости до розвиненого курорту. На вулиці від автостанції до відпочинкових баз хаотичний рух: ходять люди, сигналять машини, продають кавуни. За десяток-другий метрів з’являється тротуар, вимощений новенькою бруківкою. Він, щоправда, лише з одного боку дороги.  Меткі таксисти зарадять цій проблемі. З їхньої кількості у центрі зрозуміло, хто тут господарює: засмаглі чоловіки у шортах і шльопанцях всілися на лавочці й пильнують, коли надійде наступний автобус. Вони заробляють не тільки перевезеннями. Якщо якийсь розгублений турист не забронював собі місця для ночівлі, таксист зорієнтує, де можна спинитися. За це отримає відсоток від господаря помешкання. Реклама про оренду кімнат також є і на їхніх автівках.  Лише профспілкових баз відпочинку та дитячих таборів тут 75. Приватні підрахувати важче – більш ніж половина з них не мають навіть статусу підприємця. Який має платити лише 5% податків з доходу і близько 300 гривень у місяць єдиного соціального внеску, що  йдуть на виплати пенсій. У цьому і головна проблема, про що розповімо далі.  У червні, кажуть власники пансіонатів, для них така собі розминка порівняно з напливом туристів, який припадає на липень-серпень. Тоді тритисячне селище стає людним гамірним курортом. Туристи приїжджають з різних куточків країни, на вулицях чутно багато української мови. Але не видно, щоб цей грошовий потік зустрічала нормальна інфраструктура і сервіс.   Ціни в кафе дотягують до київських Два банкомати «Приватбанку» на все селище (інших банків просто нема). В одній такій черзі я простояла півгодини. Дехто займає чергу до банкомату і біжить скуповуватися. Ціни в кафе дотягують до київських, але персонал не особливо приязний. Можливість розрахуватися карткою у таких закладах – радше виняток, аніж правило, тож явище черг зрозуміле.  Біля автостанції, просто під палючим херсонським сонцем, жінка продає булочки й піцу, змащену майонезом. Запевняє, що все «свіженьке, щойно спечене». Туристи не перебирають, охоче купують – усе одно швидко перекусити перед дорогою більше ніде.  Попри будівельний бум, навіть у туристичному центрі селища є напіврозвалені хати. А на парканах – напівстерті шрифти ще, здається, радянської реклами з закликами не смітити й берегти воду.  Пляж чистий, піщаний. Море мілке, зручно для сімей із дітьми. Розваги та їжа на пляжі є на різний смак і ціну. 100 гривень із людини за годину їзди на катамарані, 250 гривень за зачіску з африканських косичок, 20 гривень за качан кукурудзи, 25 – за порцію креветок.  Є й геть екзотика. Пляжем походжають двоє темношкірих молодиків, з одягу на них – пов’язки на стегнах. Пропонують сфотографуватися з ними за 50 гривень. Диво, але ця атракція – одна з найпопулярніших, до хлопців шикується черга. «Дай-но я тебе торкнуся, чи ти хоч справжній», – сміється повнотіла жінка.  Улітку тут кожен залучає свій підприємницький хист, фантазію і навіть природні дані. Заробляють усі: від власників пансіонатів до місцевих, які здають кімнати в оренди. Після окупації Криму туристична індустрія дістала шанс, але сповна ним не скористалася. У Лазурному творяться історії успіху окремих підприємців, але не селища загалом.  Олена Кузик із Тернополя, релігійна молода жінка, спершу здивувалася з життєвого устрою у Лазурному. Якось у церкві її вразило, що прихожанин під час сповіді сміє відволікатися на телефонний дзвінок. «Нема ніякої святості»,  – обурилася жінка.  Різниця між мешканцями півдня і заходу спочатку видавалася критичною.  Та зрештою виявилося, що бізнес-інтереси можуть значити більше, ніж культурні відмінності. Восьмий рік, як Лазурне стало для Олени та її мами Валентини літнім домом. Вони приїжджають сюди наприкінці травня, щоб встигнути приготуватися до сезону, а їдуть уже наприкінці вересня.  Вілли ростуть одна за одною У Тернополі Олена 17 років тримає перукарню, Валентина викладає в економічному університеті. Якось подруга Валентини з Кривого Рогу розповіла про можливість придбати у Лазурному земельну ділянку й будинок для відпочивальників на один поверх. Одне тамтешнє подружжя розлучалося і ділило майно. Жінки вклали в покупку власні заощадження, підсобила сестра Валентини, яка живе в Лондоні. Був 2010 рік. Їхній пансіонат розташований у престижній частині селища, названій Аеродромом (колись тут було летовище). До моря звідси – 10 хвилин пішки. Нині ділянка на 15 сотих тут вартує 15 тисяч доларів. Вілли ростуть одна за одною. Але тоді, згадує Олена, не мали особливого бізнес-плану й мети заробляти. Вже вели один надійний бізнес у Тернополі. Тож думали: навіть якщо нічого не вийде, матимуть дачу для себе, приїжджатимуть на літо подихати морським повітрям. Та найняли майстрів – тоді ще кримських, які добре зналися на курортних пансіонатах. За кілька місяців ті добудували два поверхи з балконами і терасою, звели літню кухню. Жінки засадили виноград, щоб плівся і розростався. Коли Олена виходила на новозведену терасу, то бачила море. Мине чотири роки – і замість моря звідси виднітимуться інші новобудови. Але поки що для тернополян перший курортний сезон, і його важко назвати успішним. Пансіонат «Ванесса» міг прийняти 100 осіб у стандартних та люкс-номерах, але туристи не поспішали їхати.  «Олена телефонувала додому і просила розклеювати оголошення на стовпах. Я сказав, що це минуле століття. Вирішили створити сайт», – згадує Оленчин тато Володимир.  Лазурне оминали дорогою до Криму Наступного сезону людей побільшало, та все одно це не був ажіотаж. Їхали з сусідніх областей, із Білорусі. Але більшість потенційних туристів оминали Лазурне дорогою до Криму.  У таких умовах, згадує Олена, ще не йшлося про конкуренцію всередині селища. На території пансіонату господарі поставили пивний намет із пластиковими столиками всередині – цього вистачило на заробіток. Літо 2013-го виявилося для них останнім спокійним сезоном.  Улітку наступного року Олена схаменулася: раптом виявилося, що їхня вілла єдина з навколишніх стоїть без українського прапора. Лазурне, як уміло, демонструвало патріотизм. Після окупації Криму сюди ринули відпочивальники. «Ажіотаж виявився шаленим. Навіть невигідно стало брати завдаток із туристів. Удвічі дорожче здавали номери. Кімната коштувала 150 гривень, але відпочивальники на місці погоджувалися платити за неї 280», – згадує жінка.  Зробили ставку на умови «як удома» Відповідно, належало подбати про переваги, завдяки яким туристи вибиратимуть їхній пансіонат. Замість пивного намету з’явилася альтанка, мангал для шашликів, фонтанчик на подвір’ї. Пансіонат «Ванесса» – не з тих, що хвалиться зірками. Натомість Олена та Валентина зробили ставку на умови «як удома».  За окрему плату для туристів і мешканців сусідніх пансіонатів готують їсти. Ціна комплексного обіду – 80 гривень. Приблизно стільки ж коштуватиме обід у місцевому кафе, але Валентина переконує: все з домашніх продуктів, як для себе. Щоранку вона варить супи й борщі у трьох каструлях, витрачає на день мішок картоплі.  Нині всі 20 номерів (на 2, 3, 4 особи) у «Ваннесі» заповнені, люди бронюють місця ще з травня. Багато гостей із Дніпра, Києва, Кривого Рогу, навідуються кримські відпочивальники. З заходу України їдуть менше. З іноземців – хіба білоруси. Їдуть здебільшого сім’ями, не надто шумне Лазурне годиться для родинного відпочинку. Навідуються ті, хто вже відпочивав раніше, ті, хто чув відгуки знайомих. Завдяки «сарафанному радіо» напрацювали собі постійних клієнтів. Співпрацюють із тернопільською туристичною фірмою – кожні п’ять днів ті привозять нових туристів на базу.  Троє жінок впоруються з тим, щоб утримувати пансіонат. Крім власниць, тут є ще наймана працівниця: прибиральниця Алла з Черкащини.  Якщо в перші сезони туристи були невибагливі, то тепер Олена окидає оком сусідні пансіонати й думає, що поліпшити у своєму. Коли взимку відпочиває десь у Єгипті, оцінює тамтешні умови й міркує, що можна перейняти.  Взагалі-то Олена, випускниця економічного університету, банкір за спеціальністю, мріяла про наукову кар’єру в університеті. Навчалася в аспірантурі, писала дисертацію, та якоїсь миті все довелося покинути.  У своєму бізнесі треба уникати того, що не подобається в чужому Їй і сьогодні шкода, що наукою багато не заробиш. Зате Олена на практиці реалізувала свою історію успіху. Може виділити два її секрети. Перший, людський, – у своєму бізнесі треба уникати того, що не подобається в чужому. Кам’яні обличчя бізнесменів – це те, що має лишитися в минулому. Варто пам’ятати, коли діти твоїх клієнтів пішли до школи, цікавитися їхніми успіхами.  По-друге, бізнес має бути легальним.  Попри історії успіху окремих підприємців, Лазурне не розвивається завдяки туризму, стверджує голова селищної ради Сергій Бєлік. Більше того, він вважає, що від частини бізнесменів більше збитків, аніж користі. За підрахунками голови, близько 60 відсотків із них не зареєструвалися приватними підприємцями. Мало того, що працюють у тіні й не сплачують податків, – навіть не мають укладених договорів на вивезення сміття. Відтак – забруднюють територію.  Близько 60 відсотків не зареєстровані приватними підприємцями Бюджет селищної ради мав би наповнюватися завдяки туристичному збору. Але в Лазурному з цим багато «але», пояснює Сергій Бєлік.  27-річний чоловік прийшов головувати після того, як побував на Майдані і в АТО. Каже, в приморському Лазурному завжди точилися війни за бізнес та землю. Після одного такого корупційного скандалу (попередній голова вимагав у підприємця 90 тисяч доларів за земельні ділянки) Сергій і сів в крісло голови, перемігши на позачергових виборах. Привів із собою таких самих молодих – скажімо, новий юрисконсульт у раді ще навчається в магістратурі.  Сергій побачив, як багаторічні війни за землю і вплив породили недовіру до влади – як місцевих, так і приїжджих підприємців.  «Люди не вірять, що їхні податки можуть іти не комусь у кишеню, а на розвиток селища. Скептичні щодо того, що може щось змінитися. А без ресурсів і не зміниться», – таке ось замкнене коло.  Не платять податків як місцеві, так і нетутешні. «Для приїжджих Лазурне – плацдарм для заробітку. Вони переважно і зводять бази відпочинку. Їхнє завдання – витиснути максимум у сезон. Їх не цікавить, що відбувається з селищем після того, як вони поїдуть»,  – каже голова.  Для приїжджих Лазурне – плацдарм для заробітку Лазурненці на це дивляться – і теж не поспішають виявляти патріотизм. Мовляв, якщо власник пансіонату на сто людей не платить податків, то чому це має робити він зі своїми кімнатами на десяток відпочивальників.  Та й навіть до тієї свідомої меншості, яка оформила статус підприємців, у голови є питання. Якщо порівняти кількість баз і суму сплачених податків, стає зрозуміло, що їх надходить менше, ніж належало б. Та й підприємці вже згодом, восени, звітують податковій про кількість прийнятих за літо туристів. Перевірити, скільки відпочивальників жило насправді, неможливо. Єдина людина, в бухгалтерію якої Бєліку вдається зазирнути, – це його мама, яка теж здає кімнати в оренду.  Спершу голова гадав, що змін можна досягнути тим, що він називає «інформаційною боротьбою». Тобто, розповідати людям: те, що ви віддасте, повернеться відремонтованими дорогами, облаштованою інфраструктурою. Приїдуть більш грошовиті туристи, витрачатимуть більше, зможете запропонувати їм дорожчі послуги. Як приклад, наводить село Щасливцеве у Генічеському районі, де підприємці легалізовані і сплачують податки. Отримують кілька мільйонів прибутку і є туристичними лідерами в регіоні.  Така тактика виправдала себе лише частково. Якщо у 2016-му від туристичного збору надійшло 36 тисяч гривень, то торік удвічі більше: 74 тисячі гривень. Усе одно це мізер для селища.  Інше потенційне джерело доходу – акцизні податки на алкоголь і сигарети. Та і з цим негусто: торік зібрали 200 тисяч гривень зі всіх магазинів.  «Цього вистачає, хіба щоб замостити ями на одній вулиці. Враховуючи, скільки тут у сезон випивається і викурюється, сума має бути мінімум у десять разів більшою. Але в магазині товар пропускають поза касою», – нарікає голова.  Тож Бєлік вирішив не лише словами привчати підприємців до порядку. Інспектор із благоустрою перевіряє, чи всі вивозять сміття, чи викошують бур’яни навколо своєї ділянки. Але зміни відбуваються так повільно і вони настільки малопомітні для стороннього ока, що в селищного голови вже вичахає ентузіазм. Сергій уже сумнівається, чи подаватися йому на наступну каденцію.  «Селище почне змінюватися лише тоді, коли цього захочуть самі люди. Без їхньої участі і відповідальності залишатимемось напівлегальним курортом із розбитими дорогами», – каже Бєлік.\n",
      "Original summary: Трагедія спільного: Лазурне не стане справжнім курортом, поки люди не платитимуть податків\n",
      "\n",
      "Text\n",
      "  Word Ids:    [35315, 1512, 3314, 1537, 33046, 11298, 35316, 35317, 746, 35318, 35319, 14364, 35320, 1890, 5002, 1406, 35321, 5674, 1318, 2911, 9057, 13048, 863, 28973, 61604, 35322, 35323, 4367, 6409, 1512, 35324, 35325, 35326, 9759, 5381, 5706, 2885, 4796, 35327, 35328, 737, 31194, 35329, 35330, 17354, 35331, 35332, 12693, 24082, 549, 35333, 4209, 35334, 13677, 35335, 915, 35336, 35337, 61604, 35338, 6288, 9342, 21843, 871, 3450, 10409, 35339, 3396, 35340, 35341, 14364, 9919, 3976, 35342, 3118, 3452, 35343, 5141, 6744, 91, 6385, 29178, 2887, 1616, 1182, 4945, 4775, 1569, 1905, 21668, 6968, 35344, 552, 12356, 34087, 4230, 8141, 35345, 3517, 3951, 624, 35346, 35347, 3715, 18968, 27125, 10448, 10340, 9127, 61604, 13791, 484, 61604, 61604, 1404, 26083, 15233, 268, 17274, 1373, 7427, 18175, 1477, 425, 7786, 26065, 727, 35348, 24068, 29601, 1389, 1695, 808, 35349, 1596, 35350, 14863, 13791, 16969, 3498, 16853, 2166, 35351, 18978, 5563, 5166, 3900, 35352, 22892, 61604, 1695, 808, 35349, 1596, 15531, 35353, 1721, 26117, 35354, 3183, 25048, 16550, 18636, 17790, 375, 3280, 7776, 21275, 8626, 35318, 35355, 35356, 24783, 8474, 26228, 35357, 35358, 35359, 35360, 16163, 35361, 10428, 61604, 26083, 35362, 25507, 2242, 4919, 743, 35363, 13016, 12061, 2158, 20606, 1232, 33025, 2885, 13823, 35364, 1229, 35365, 61604, 35366, 19, 3617, 28022, 35367, 20693, 2260, 33059, 35094, 35226, 18893, 35368, 2953, 18878, 3975, 35246, 26292, 24935, 20212, 23393, 6208, 6653, 1569, 2614, 24105, 18370, 35369, 22235, 1569, 30397, 22445, 35370, 42, 1569, 35371, 21550, 4868, 35372, 35111, 24862, 35087, 35373, 19077, 35374, 35375, 1065, 377, 5298, 35376, 2980, 35377, 1003, 1569, 20420, 35378, 83, 9193, 21004, 35379, 21065, 12378, 6043, 35380, 212, 5145, 61604, 8474, 10473, 27640, 2039, 28946, 30489, 11590, 7932, 588, 549, 7971, 35346, 3729, 19124, 5960, 19098, 2203, 1494, 27118, 1016, 35381, 4824, 19182, 24913, 33046, 35382, 1067, 10533, 6633, 19524, 13823, 5752, 18957, 35383, 35384, 19945, 10521, 8474, 14885, 35385, 21816, 6532, 33046, 6974, 211, 35386, 35387, 35388, 35389, 8151, 35390, 9709, 3498, 7783, 35391, 35392, 8474, 14844, 35393, 28621, 2683, 35394, 35395, 3548, 12004, 416, 5665, 35396, 20291, 3281, 1401, 1340, 20247, 11039, 33096, 25826, 14817, 15233, 844, 4727, 157, 5483, 35397, 16180, 688, 6089, 4727, 18465, 7420, 1481, 83, 18355, 11738, 18957, 2961, 2454, 35398, 33171, 25471, 27851, 22726, 6974, 32019, 33096, 14821, 14822, 8113, 1721, 7126, 33046, 2475, 15359, 2500, 33016, 10109, 5727, 35399, 20814, 61604, 61604, 15338, 571, 11087, 23981, 1063, 2556, 61604, 21179, 33096, 1231, 35400, 13429, 3291, 35401, 7121, 35402, 5446, 13823, 35403, 35404, 446, 35405, 13099, 2652, 1, 15149, 4737, 27544, 824, 2231, 6209, 824, 2243, 7420, 1481, 83, 18355, 4107, 18957, 4191, 1099, 416, 18599, 10718, 1200, 22632, 35406, 416, 11738, 3280, 14856, 6915, 8563, 35407, 35408, 32394, 18590, 19569, 18592, 12053, 7735, 35409, 35410, 35411, 35412, 1123, 27255, 35413, 35414, 35415, 7512, 35416, 35291, 571, 35417, 35022, 61604, 35418, 18957, 8047, 61604, 35419, 16911, 18893, 20811, 1726, 13099, 61604, 35420, 35421, 35422, 2743, 4185, 4924, 20035, 35401, 35423, 5423, 6653, 4349, 19995, 35424, 21866, 26083, 29014, 13689, 18957, 35425, 7378, 35426, 35427, 5692, 35428, 4362, 2932, 6994, 408, 14383, 4107, 61604, 9797, 3769, 1401, 35429, 13016, 1494, 1294, 16180, 1618, 2206, 4919, 35430, 23219, 13081, 6184, 2169, 539, 21671, 27125, 35429, 1401, 13016, 1494, 3183, 2072, 4107, 18957, 2092, 16445, 4028, 13823, 1587, 35431, 35432, 6275, 31766, 35433, 35434, 35059, 4028, 25416, 25652, 32394, 4314, 2112, 12004, 16095, 20204, 35435, 10473, 1294, 18957, 35436, 12004, 8166, 16780, 9906, 13410, 651, 1958, 23364, 1401, 35437, 35438, 8203, 2203, 1494, 844, 35439, 35440, 35430, 8846, 35441, 10437, 1340, 865, 35442, 27125, 11719, 6435, 35443, 20349, 3432, 27237, 14006, 1569, 35440, 1369, 35444, 2887, 19890, 4107, 8474, 3551, 11489, 1188, 8273, 3608, 15654, 24418, 11002, 3401, 5184, 26083, 35445, 3291, 35401, 1726, 35446, 35447, 9011, 35448, 31750, 35449, 35450, 31150, 2006, 35401, 35423, 29346, 7741, 4350, 18957, 33171, 3551, 11489, 1188, 8273, 5666, 2630, 27125, 3730, 13081, 35346, 3402, 10772, 1210, 34338, 35451, 3286, 1569, 5749, 2178, 6434, 22766, 12916, 808, 33171, 16207, 29140, 10771, 10454, 27791, 35452, 35453, 771, 35454, 35455, 21067, 35456, 4737, 42, 17696, 66, 1461, 1758, 14690, 61604, 35457, 1406, 35143, 915, 157, 3803, 7120, 740, 14821, 14822, 35458, 15208, 35440, 2683, 74, 688, 2839, 35139, 688, 4059, 28981, 2395, 61604, 1401, 10434, 35459, 9919, 35458, 35460, 7219, 24167, 11792, 3401, 61604, 3963, 35461, 19660, 15557, 3585, 35462, 26956, 19093, 351, 248, 6654, 7130, 397, 27125, 14333, 5138, 738, 61604, 16192, 35401, 35463, 35464, 4987, 35465, 32103, 35466, 3196, 16165, 26083, 30237, 18957, 61604, 9821, 3526, 35467, 8852, 21334, 703, 12797, 24934, 4655, 35468, 23210, 25757, 1188, 24391, 35469, 2888, 18957, 35470, 12915, 17806, 35471, 35472, 31936, 10323, 4418, 4419, 22726, 27092, 35473, 13105, 2340, 3457, 10421, 6829, 35474, 703, 14590, 11145, 7700, 35475, 11126, 35476, 31935, 18957, 5571, 35477, 2458, 10533, 5191, 2399, 35478, 703, 14590, 11145, 7700, 35475, 7537, 7585, 10015, 15712, 35479, 16421, 507, 461, 26384, 8426, 15557, 9738, 1939, 35480, 5408, 24847, 497, 416, 35481, 2158, 1067, 10533, 6633, 19524, 1401, 9828, 3401, 30870, 5053, 5618, 18908, 4192, 2611, 35482, 2207, 4015, 15712, 22796, 17790, 10496, 14060, 438, 0, 35483, 18667, 28003, 984, 25844, 29187, 1182, 91, 25804, 1002, 19128, 505, 12707, 35484, 7885, 0, 33394, 18667, 28003, 719, 18908, 4192, 4244, 35485, 3401, 33025, 14369, 33046, 4941, 2611, 35482, 2644, 10372, 3689, 2758, 35486, 25036, 9045, 1632, 35487, 33046, 35488, 695, 416, 2326, 1226, 35489, 15357, 8516, 5618, 4928, 29178, 1137, 2243, 28273, 8032, 2611, 35490, 18305, 438, 35491, 34067, 6664, 11992, 3183, 1483, 4198, 297, 35492, 4559, 35493, 35494, 2611, 7177, 35495, 695, 2326, 2040, 30432, 3756, 141, 3729, 33021, 19524, 1406, 2790, 5103, 1270, 13872, 17618, 11751, 1763, 13823, 35496, 33481, 8001, 2775, 32132, 4159, 628, 1182, 3793, 61604, 33021, 1401, 35497, 16091, 5251, 7579, 316, 9919, 5657, 3261, 35498, 5167, 2743, 5326, 635, 35499, 23990, 5618, 33021, 1401, 35497, 16091, 61604, 10866, 1416, 3257, 8203, 4090, 2809, 35431, 2792, 1618, 1170, 1182, 254, 3958, 35500, 9057, 33016, 35501, 35502, 35503, 10221, 19524, 438, 667, 4334, 1235, 14364, 12203, 35504, 1182, 484, 4796, 35505, 15654, 25949, 4194, 4313, 30608, 35506, 1235, 35507, 32394, 27125, 4904, 33016, 35508, 1924, 749, 9906, 2768, 35509, 61604, 18679, 4361, 8476, 7396, 5960, 10409, 14885, 5618, 35510, 2211, 29096, 4802, 16378, 25078, 3162, 5076, 3011, 35511, 8669, 35512, 35513, 61604, 29573, 31700, 35514, 26083, 35515, 21411, 14984, 26116, 9466, 752, 11392, 1275, 61604, 35516, 4170, 25949, 35517, 29187, 1270, 1577, 2236, 33010, 16138, 12820, 5707, 35518, 4070, 4762, 3199, 33014, 14369, 3395, 6149, 1569, 3765, 11719, 2965, 1852, 1569, 4919, 35519, 13823, 35520, 14241, 4945, 35521, 1270, 30679, 35522, 35523, 3765, 25612, 1772, 1569, 11271, 658, 35524, 28981, 746, 7931, 2743, 61604, 61604, 9345, 5016, 2253, 18392, 20175, 9978, 35525, 1320, 1321, 24481, 5618, 3280, 35482, 2502, 3748, 35526, 19524, 14503, 5652, 35527, 6317, 2594, 505, 61604, 32448, 32449, 8032, 1397, 10656, 2163, 6772, 35528, 35529, 28209, 35530, 438, 61604, 12636, 2611, 6089, 25270, 25668, 35531, 35532, 13791, 32639, 35533, 35534, 1406, 5381, 9902, 3799, 61604, 61604, 1404, 35535, 35513, 35482]\n",
      "  Input Words: побиті дороги перше розповість лазурному рости розвиненого курорту вулиці автостанції відпочинкових баз хаотичний рух ходять люди сигналять машини продають кавуни десяток метрів являється тротуар <UNK> новенькою бруківкою щоправда боку дороги меткі таксисти зарадять проблемі їхньої кількості центрі зрозуміло господарює засмаглі чоловіки шортах шльопанцях всілися лавочці пильнують надійде наступний автобус заробляють перевезеннями якийсь розгублений турист забронював місця ночівлі таксист <UNK> спинитися отримає відсоток господаря помешкання реклама оренду кімнат їхніх автівках профспілкових баз відпочинку дитячих таборів 75 приватні підрахувати важче половина мають статусу підприємця платити 5 податків доходу 300 гривень місяць єдиного соціального внеску йдуть виплати пенсій головна проблема розповімо червні кажуть власники пансіонатів розминка порівняно напливом туристів припадає липень серпень <UNK> селище стає <UNK> <UNK> курортом туристи приїжджають різних куточків країни вулицях чутно української мови видно грошовий потік зустрічала нормальна інфраструктура сервіс ціни кафе дотягують київських банкомати приватбанку селище банків нема такій черзі простояла півгодини дехто займає чергу банкомату біжить <UNK> ціни кафе дотягують київських персонал приязний можливість розрахуватися карткою таких закладах радше виняток аніж правило тож явище черг зрозуміле автостанції палючим херсонським сонцем жінка продає булочки піцу змащену майонезом запевняє свіженьке щойно <UNK> туристи перебирають охоче купують одно швидко перекусити дорогою ніде попри будівельний бум туристичному центрі селища напіврозвалені хати парканах <UNK> шрифти радянської реклами закликами смітити берегти воду пляж чистий піщаний море мілке зручно сімей дітьми розваги їжа пляжі різний смак ціну 100 гривень людини годину їзди катамарані 250 гривень зачіску африканських косичок 20 гривень качан кукурудзи 25 порцію креветок екзотика пляжем походжають двоє темношкірих молодиків одягу пов язки стегнах пропонують сфотографуватися 50 гривень диво атракція одна найпопулярніших хлопців шикується черга дай но торкнуся справжній сміється <UNK> жінка улітку залучає свій підприємницький хист фантазію природні дані заробляють власників пансіонатів місцевих здають кімнати оренди окупації криму туристична індустрія дістала шанс сповна скористалася лазурному творяться історії успіху окремих підприємців селища загалом олена кузик тернополя релігійна молода жінка спершу здивувалася життєвого устрою лазурному якось церкві вразило прихожанин сповіді сміє відволікатися телефонний дзвінок нема ніякої святості обурилася жінка різниця мешканцями півдня заходу видавалася критичною зрештою виявилося бізнес інтереси значити культурні відмінності лазурне стало олени мами валентини літнім домом приїжджають сюди наприкінці травня встигнути приготуватися сезону їдуть уже наприкінці вересня вілли ростуть одна одною тернополі олена 17 тримає перукарню валентина викладає економічному університеті якось подруга валентини кривого рогу розповіла можливість придбати лазурному земельну ділянку будинок відпочивальників поверх одне тамтешнє подружжя <UNK> <UNK> майно жінки вклали покупку власні заощадження <UNK> сестра валентини живе лондоні 2010 їхній пансіонат розташований престижній частині селища названій аеродромом колись летовище моря 10 хвилин пішки нині ділянка 15 сотих вартує 15 доларів вілли ростуть одна одною згадує олена мали особливого бізнес плану мети заробляти вели надійний бізнес тернополі тож думали вийде матимуть дачу приїжджатимуть літо подихати морським повітрям найняли майстрів кримських зналися курортних пансіонатах місяців добудували поверхи балконами терасою звели літню кухню жінки засадили виноград <UNK> розростався олена виходила <UNK> терасу бачила море мине замість моря <UNK> новобудови тернополян курортний сезон важко назвати успішним пансіонат ванесса прийняти 100 осіб стандартних люкс номерах туристи поспішали їхати олена телефонувала додому просила розклеювати оголошення стовпах минуле століття вирішили створити сайт згадує <UNK> тато володимир лазурне оминали дорогою криму наступного сезону людей побільшало одно ажіотаж їхали сусідніх областей білорусі більшість потенційних туристів оминали лазурне дорогою криму таких умовах згадує олена йшлося конкуренцію всередині селища території пансіонату господарі поставили пивний намет пластиковими столиками всередині вистачило заробіток літо 2013 го виявилося останнім спокійним сезоном улітку наступного олена схаменулася виявилося їхня вілла єдина навколишніх стоїть українського прапора лазурне уміло демонструвало патріотизм окупації криму сюди ринули відпочивальники ажіотаж виявився шаленим невигідно стало брати завдаток туристів удвічі дорожче здавали номери кімната коштувала 150 гривень відпочивальники місці погоджувалися платити 280 згадує жінка зробили ставку умови удома відповідно належало подбати переваги завдяки яким туристи вибиратимуть їхній пансіонат замість пивного намету явилася альтанка мангал шашликів фонтанчик подвір ї пансіонат ванесса хвалиться зірками натомість олена валентина зробили ставку умови удома окрему плату туристів мешканців сусідніх пансіонатів готують їсти ціна комплексного обіду 80 гривень приблизно стільки коштуватиме обід місцевому кафе валентина переконує домашніх продуктів щоранку варить супи борщі трьох каструлях витрачає мішок картоплі нині 20 номерів 2 3 4 особи <UNK> заповнені люди бронюють місця травня гостей дніпра києва кривого рогу навідуються кримські відпочивальники заходу україни їдуть іноземців білоруси їдуть здебільшого ями надто <UNK> лазурне годиться родинного відпочинку навідуються відпочивав чув відгуки знайомих завдяки <UNK> радіо напрацювали постійних клієнтів співпрацюють тернопільською туристичною фірмою п ять днів привозять нових туристів базу троє жінок <UNK> утримувати пансіонат власниць наймана працівниця прибиральниця алла черкащини перші сезони туристи невибагливі олена <UNK> оком сусідні пансіонати думає поліпшити своєму взимку відпочиває десь єгипті оцінює тамтешні умови міркує перейняти взагалі олена випускниця економічного університету банкір спеціальністю мріяла наукову кар єру університеті навчалася аспірантурі писала дисертацію якоїсь миті довелося покинути своєму бізнесі уникати подобається чужому шкода наукою заробиш олена практиці реалізувала історію успіху виділити секрети людський своєму бізнесі уникати подобається чужому кам яні обличчя бізнесменів лишитися минулому варто пам ятати діти клієнтів пішли школи цікавитися їхніми успіхами друге бізнес легальним попри історії успіху окремих підприємців лазурне розвивається завдяки туризму стверджує голова селищної ради сергій бєлік вважає частини бізнесменів збитків аніж користі підрахунками голови 60 зареєструвалися приватними підприємцями працюють тіні сплачують податків мають укладених договорів вивезення сміття відтак забруднюють територію 60 зареєстровані приватними підприємцями бюджет селищної ради мав наповнюватися завдяки туристичному збору лазурному пояснює сергій бєлік 27 річний чоловік прийшов головувати побував майдані ато приморському лазурному точилися війни бізнес землю такого корупційного скандалу попередній голова вимагав підприємця 90 доларів земельні ділянки сергій сів крісло голови перемігши позачергових виборах привів таких молодих скажімо новий юрисконсульт раді навчається магістратурі сергій побачив багаторічні війни землю вплив породили недовіру влади місцевих приїжджих підприємців люди вірять їхні податки іти комусь кишеню розвиток селища скептичні змінитися ресурсів зміниться замкнене коло платять податків місцеві <UNK> приїжджих лазурне плацдарм заробітку переважно зводять бази відпочинку їхнє завдання витиснути максимум сезон цікавить відбувається селищем поїдуть голова приїжджих лазурне плацдарм заробітку <UNK> дивляться поспішають виявляти патріотизм мовляв власник пансіонату сто людей платить податків робити своїми кімнатами десяток відпочивальників свідомої меншості оформила статус підприємців голови питання порівняти кількість баз суму сплачених податків стає зрозуміло надходить належало підприємці згодом восени звітують податковій кількість прийнятих літо туристів перевірити відпочивальників жило насправді неможливо єдина людина бухгалтерію <UNK> вдається зазирнути мама здає кімнати оренду спершу голова гадав змін досягнути називає інформаційною боротьбою тобто розповідати людям віддасте повернеться відремонтованими дорогами <UNK> інфраструктурою приїдуть грошовиті туристи витрачатимуть зможете запропонувати дорожчі послуги приклад наводить село <UNK> генічеському районі підприємці легалізовані сплачують податки отримують прибутку туристичними лідерами регіоні тактика виправдала частково 2016 му туристичного збору надійшло 36 гривень торік удвічі 74 тисячі гривень одно мізер селища потенційне джерело доходу акцизні податки алкоголь сигарети негусто торік зібрали 200 гривень магазинів вистачає замостити ями вулиці враховуючи сезон <UNK> <UNK> сума мінімум разів більшою магазині товар пропускають поза касою нарікає голова тож бєлік вирішив словами привчати підприємців порядку інспектор благоустрою перевіряє вивозять сміття <UNK> бур яни ділянки зміни відбуваються повільно настільки малопомітні стороннього ока селищного голови <UNK> ентузіазм сергій уже сумнівається подаватися наступну каденцію селище почне змінюватися захочуть люди їхньої участі відповідальності <UNK> <UNK> курортом розбитими дорогами бєлік\n",
      "\n",
      "Summary\n",
      "  Word Ids:       [7048, 30589, 24972, 30589, 24972, 48206]\n",
      "  Response Words: різноманітні львівську продюсери львівську продюсери євдокімова\n"
     ]
    }
   ],
   "source": [
    "# Create your own review or use one from the dataset\n",
    "#input_sentence = \"I have never eaten an apple before, but this red one was nice. \\\n",
    "                  #I think that I will try a green apple next time.\"\n",
    "#text = text_to_seq(input_sentence)\n",
    "random = np.random.randint(0,len(clean_texts))\n",
    "input_sentence = clean_texts[random]\n",
    "text = text_to_seq(clean_texts[random])\n",
    "\n",
    "checkpoint = \"best_model.ckpt\"\n",
    "\n",
    "loaded_graph = tf.Graph()\n",
    "with tf.Session(graph=loaded_graph) as sess:\n",
    "    # Load saved model\n",
    "    loader = tf.train.import_meta_graph(checkpoint + '.meta')\n",
    "    loader.restore(sess, checkpoint)\n",
    "\n",
    "    input_data = loaded_graph.get_tensor_by_name('input:0')\n",
    "    logits = loaded_graph.get_tensor_by_name('predictions:0')\n",
    "    text_length = loaded_graph.get_tensor_by_name('text_length:0')\n",
    "    summary_length = loaded_graph.get_tensor_by_name('summary_length:0')\n",
    "    keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "    \n",
    "    #Multiply by batch_size to match the model's input parameters\n",
    "    answer_logits = sess.run(logits, {input_data: [text]*batch_size, \n",
    "                                      summary_length: [np.random.randint(5,8)], \n",
    "                                      text_length: [len(text)]*batch_size,\n",
    "                                      keep_prob: 1.0})[0] \n",
    "\n",
    "# Remove the padding from the tweet\n",
    "pad = vocab_to_int[\"<PAD>\"] \n",
    "\n",
    "print('Original Text:', articles.article[random])\n",
    "print('Original summary:', articles.title[random])#clean_summaries[random]\n",
    "\n",
    "print('\\nText')\n",
    "print('  Word Ids:    {}'.format([i for i in text]))\n",
    "print('  Input Words: {}'.format(\" \".join([int_to_vocab[i] for i in text])))\n",
    "\n",
    "print('\\nSummary')\n",
    "print('  Word Ids:       {}'.format([i for i in answer_logits if i != pad]))\n",
    "print('  Response Words: {}'.format(\" \".join([int_to_vocab[i] for i in answer_logits if i != pad])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h5zINNiDlQXZ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "rnnlstm.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
